% TO-DO
  % números en los comentarios aparecen en negro (debería prevalecer el comentario)
  % quitar los newpage que he tenido que meter para q no se me fastidien los footnotes

% Spell checker settings
% spell-checker: disable

\documentclass{article}

% Paquetes usados
\usepackage{graphicx} % Imágenes
\usepackage{amsmath} % Algunos símbolos matemáticos
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{array} % Matrices, tablas
\usepackage{xcolor} % Colores de texto
\usepackage{enumitem} % Listas con letras
\usepackage[spanish]{babel} % Español
\usepackage{url}
%LEAN
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{color}
\definecolor{keywordcolor}{rgb}{0.8, 0.1, 0.1}   % red
\definecolor{tacticcolor}{rgb}{0.0, 0.4, 0.9}    % blue
\definecolor{commentcolor}{rgb}{0.4, 0.4, 0.4}   % grey
\definecolor{symbolcolor}{rgb}{0.0, 0.4, 0.9}    % blue
\definecolor{sortcolor}{rgb}{0.1, 0.5, 0.1}      % green
\definecolor{attributecolor}{rgb}{0.7, 0.1, 0.1} % red
\definecolor{backgroundcolor}{rgb}{0.92, 0.92, 0.92} % light grey
\definecolor{contextcolor}{rgb}{0.9, 0.4, 0.1} %orange

% Distancias entre párrafos, quitar sangrías
\setlength{\parindent}{0pt}
\setlength{\parskip}{.8em}

% Espaciados entre palabras en el justificado.
\sloppy

% Título
\title{Formalización de las matemáticas con Lean. Un caso de estudio: Resultados de Topología General.}
\author{Pepa Montero Jimena}
\date{}

% Inline code
\usepackage{tikz}
\tikzset{%
    baseline,
    inner sep=2pt,
    minimum height=12pt,
    rounded corners=2pt  
}
\newcommand{\code}[1]{\mbox{% added this percent
    \ttfamily
    \tikz \node[anchor=base,fill=backgroundcolor]{#1};% added this percent
}}
\newcommand{\bluecode}[1]{\code{\textcolor{tacticcolor}{#1}}}
\newcommand{\blue}[1]{\textcolor{tacticcolor}{#1}}
\newcommand{\redcode}[1]{\code{\textcolor{keywordcolor}{#1}}}

% Lean code
\def\lstlanguagefiles{lstlean.tex, infoview.tex}
\lstset{language=lean, backgroundcolor=\color{backgroundcolor}} %default language

% Infoview


% Math commands
\newcommand{\nat}{\mathbb{N}}
\newcommand{\rat}{\mathbb{Q}}

% Other commands
\newcommand{\refpep}[1]{(\ref{#1})}
\newcommand{\quotes}[1]{``#1''}

% Theorem environments
\newtheorem{definition}{Definición}[section]
\newtheorem{proposition}{Proposición}[section]



\begin{document}

\maketitle
\tableofcontents


\section{Introducción}

Introducción al trabajo.



\noindent
\begin{minipage}[t]{0.58\textwidth}
\begin{lstlisting}[language=lean]
  example (p q : Prop) (hp : p) (hq : q) : p ∧ q := by
    exact And.intro hp hq
\end{lstlisting}
\end{minipage}%
\hfill
\begin{minipage}[t]{0.40\textwidth}
  \begin{lstlisting}[language=infoview]
  Tactic state
    ŋ1 goalŋ
    ħp qħ : Prop
    ħhpħ : p
    ħhqħ : q
    ⊢ p ∧ q\end{lstlisting}
\end{minipage}


\newpage

\section{Lean Theorem Prover}

A medida que las matemáticas se vuelven más técnicas y especializadas, verificar con rigor las demostraciones formales es una tarea cada vez más costosa. Con la motivación de facilitarla, en las últimas décadas ha surgido un interés por la verificación computacional de teoremas, dando lugar al desarrollo de sistemas como Lean, Coq o Isabelle.

Dentro de este campo, distinguimos dos tipos de sistemas de verificación formal: interactivos (ITP), que proporcionan un entorno en el que usuario guía el proceso de la demostración paso a paso, centrándose en el aspecto de "verificación", y automáticos (ATP), que buscan completar demostraciones de manera completamente autónoma \cite[Sección~1]{avigad2024theorem}.

En este trabajo nos centraremos en el uso de \textbf{Lean Theorem Prover}, introducido en 2013 por Leonardo de Moura desde Microsoft Research. Se trata de un verificador cuyo objetivo es reducir la distancia entre demostraciones asistidas y automatizadas, combinando un lenguaje basado en la teoría de tipos dependientes con herramientas que permiten delegar subproblemas sencillos al sistema

Aunque aquí nos limitaremos a su uso como asistente de demostración, Lean es también un lenguaje de programación funcional completo, lo que ofrece amplias posibilidades de personalización y automatización al usuario \cite[Sección~1]{avigad2024theorem}.

En este sistema, es posible definir objetos matemáticos, especificar propiedades sobre ellos y demostrar que dichas propiedades se cumplen. Esta tarea se ve facilitada por \textit{Mathlib}, una extensa biblioteca de matemáticas formalizadas en Lean desarrollada colaborativamente por una comunidad activa y en constante crecimiento \cite{mathlib}.

Las demostraciones son verificadas automáticamente por el núcleo lógico de Lean, que garantiza su corrección mediante un sistema de tipos expresivo y riguroso. La fiabilidad de Lean como asistente de demostración reside precisamente en la simplicidad y robustez de este núcleo \cite{bailey2024type}.

En esta sección seguiremos principalmente el manual en línea \textit{Theorem Proving in Lean 4}~\cite{avigad2024theorem} que es una versión actualizada del libro \textit{Theorem Proving in Lean}~\cite{avigad2021theorem} publicado en 2021 para adaptarse a la nueva versión de Lean. A nivel teórico, no existe una gran diferencia entre los dos, por lo que ambas referencias son válidas para comprender los fundamentos que exponemos aquí.


\subsection{La teoría de tipos de Lean}

La teoría de conjuntos de Zermelo-Fraenkel con el axioma de elección (ZFC) es la base fundacional elegida para formalizar la mayoría de las matemáticas que conocemos. En este marco, todos los objetos matemáticos (números, funciones, estructuras algebraicas, etc.) pueden representarse como conjuntos, construidos a partir de unos pocos axiomas básicos.

Sin embargo, este sistema carece de una estructura interna diferenciada: todo objeto matemático, como un número, una función o incluso una colección de funciones son, en última instancia, conjuntos. Para lograr una representación más clara y diferenciada de los objetos matemáticos, Lean utiliza, en su lugar, un sistema basado en tipos. Además, este enfoque nos ofrece la posibilidad de establecer una correspondencia entre programas y demostraciones matemáticas, conocida como la correspondencia de Curry-Howard\footnote{La correspondencia de Curry-Howard establece una relación entre lógica y programación; permite entender como pueden ser equivalentes \quotes{demostrar una proposición} y \quotes{construir un término de cierto tipo}. Veremos qué quiere decir esto en la práctica más adelante, pero las ideas más profundas, que quedan fuera del alacance de este trabajo, se exponen detalladamente en \cite{sorensen2006lectures}.}.

En particular, Lean se fundamenta en el \textit{Cálculo de Construcciones Inductivas}, una extensión del cálculo de tipos dependientes que incorpora tipos inductivos y una jerarquía numerable no cumulativa de universos \cite{coquand1986calculus}. Aunque no es necesario entender este sistema para utilizar Lean como asistente de demostración, a continuación daremos una breve explicación de los conceptos fundamentales.

En esta sección, veremos varios fragmentos de código en Lean. Lean cuenta con un compilador interactivo que procesa cada línea cuando el cursor se encuentra sobre ella, mostrando el resultado por pantalla. A partir de ahora, los comentarios que acompañan al código reflejan la salida que Lean devuelve en cada línea. Los comentarios en Lean se escriben empezando con doble guión ($--$) y están en color gris.

\subsubsection{Teoría de tipos}

Empecemos por lo más básico: la teoría de tipos. Cambiamos el foco de \quotes{cada objeto es un conjunto }, propio de ZFC, a \quotes{cada objeto es un término con un tipo asociado}. Esto nos permite estructurar con mayor claridad los objetos matemáticos y sus relaciones.

Por ejemplo, $3$ es un término de tipo \quotes{natural} ($\mathbb{N}$), mientras que \quotes{true} es un término de tipo \quotes{booleano}. En Lean podemos comprobar el tipo de estas expresiones utilizando el comando \bluecode{\#check}\footnote{En Lean, podemos escribir $\mathbb{N}$ escribiendo \code{$\backslash$nat} en el editor y luego pulsando espacio. En general, escribiremos los símbolos matemáticos de esta forma. Una lista comprensiva con los símbolos utilizados en el proyecto y sus respectivos comandos se puede encontrar en (un anexo)}:


\begin{lstlisting}
  #check 3    -- 3 : ℕ 
  #check true   -- Bool.true : Bool
\end{lstlisting}

Como en este ejemplo, en Lean utilizamos el símbolo $:$ para describir la información sobre el tipado. Es decir, si $x$ es un término de tipo $X$, escribimos $x : X$.

Por otro lado, un tipo, como es $\mathbb{N}$, también es un término. Podemos comprobar su tipo:

\begin{lstlisting}
  #check ℕ    -- ℕ : Type
\end{lstlisting}

En Lean, los tipos tienen su propio tipo, que recibe el nombre de \code{Type}. Esto nos permite definir nuevos tipos. Podemos utilizar el comando \bluecode{variable} para definir objetos en nuestro código\footnote{Veremos este comando en detalle más adelante}.

\begin{lstlisting}
  variable (X : Type)
  #check X    -- X : Type
  variable (x : X)
  #check x    -- x : X
\end{lstlisting}

Ahora, podemos combinar distintos tipos para obtener tipos más complejos. Sean $X$ e $Y$ dos tipos. Podemos considerar el tipo $X \times Y$, que denota los pares formados por un elemento de $X$ y otro de $Y$. El tipo que más utilizaremos es $X \to Y$, que denota las funciones de $X$ en $Y$. Escribimos esto en Lean.

\begin{lstlisting}
  variable (X Y : Type)
  #check X × Y    -- X × Y : Type
  variable (x : X) (y : Y)
  #check (x, y)    -- (x, y) : X × Y
  
  #check X → Y    -- X → Y : Type
  variable (f : X → Y)
  #check f    -- f : X → Y
\end{lstlisting}

Por otro lado, a partir de la yuxtaposición de términos simples, podemos formar términos más complejos. En Lean, las reglas de tipado dictan el tipo de estos nuevos términos obtenidos. Por ejemplo, si $x$ es de tipo $X$ y $f$ es de tipo $A \to B$, como en el ejemplo anterior, entonces $f x$ tiene tipo $B$. En efecto:

\begin{lstlisting}
  #check f x    -- f x : Y
\end{lstlisting}

La capacidad de Lean para identificar el tipo de un término sin necesidad de que el usuario lo especifique se conoce como \textbf{inferencia de tipos}. Como veremos más adelante, este proceso ocurre de manera automática en su núcleo y es el aspecto crucial de la verificación de demostraciones.

\subsubsection{Teoría de tipos dependientes}

Para poder expresar los distintos objetos matemáticos en esta teoría, es importante que un tipo no sea necesariamente estático, sino que pueda depender de otros términos.

Por ejemplo, \code{Fin} es un tipo en Lean que describe los números naturales menores que otro número natural dado. Precisamente, no tiene sentido afirmar que un término tiene tipo \code{Fin}, porque \code{Fin} depende de este número dado: un término de tipo \code{$\mathbb{N}$}. En efecto,

\begin{lstlisting}
  #check Fin    -- Fin (n : ℕ) : Type
  #check Fin 5    -- Fin 5 : Type
\end{lstlisting}

Decimos que \code{Fin} es un tipo dependiente, porque depende del valor de n. Lean admite, por tanto, tipos dependientes en su teoría.

\subsubsection{Cálculo de Construcciones}

El Cálculo de Construcciones es una extensión del Cálculo Lambda con tipos \cite{coquand1986calculus}. El Cálculo Lambda, introducido por Alonzo Church en los años 1930, es un sistema formal en el que todos los términos se ven como funciones (o abstracciones) y se operan entre sí mediante aplicación de funciones (el uso de una función sobre un argumento) \cite{pierce2002types}. A pesar de su simplicidad, este sistema se ha convertido en la base formal de muchos lenguajes de programación modernos.

Por ejemplo, una función válida podría ser $n \mapsto 2n : \mathbb{N} \rightarrow \mathbb{N}$, que representa una función que, al ser aplicada a un número natural, devuelve el número multiplicado por dos.

En Lean, definimos funciones utilizando el comando \code{fun}\footnote{En la versión anterior de Lean, se utilizaba la notación \code{$\lambda$ n, 2 * n}, más similar a la del Cálculo Lambda, sin embargo en esta última versión se ha cambiado a \code{fun n $\mapsto$ 2 * n} para mejorar la legibilidad del código.}, por ejemplo\footnote{Estudiaremos el comando \bluecode{def} en detalle más adelante.}:

\begin{lstlisting}
  def f : ℕ → ℕ := fun n ↦ 2 * n
\end{lstlisting}

Además, se puede definir una reducción sobre este tipo de términos: el término formado por la anterior función aplicada a $3$, $(n \mapsto 2n)3$, se puede reducir a $2 \cdot 3$ por aplicación funcional, y luego a $6$ por definición de la multiplicación.

Podemos comprobar el resultado de esta reducción utilizando el comando \bluecode{\#eval}.

\begin{lstlisting}
  #eval f 3    -- 6
\end{lstlisting}

Diremos que dos términos que pueden reducirse de esta manera al mismo valor son \textbf{iguales por definición}. Lean trata términos que sean iguales por definición como literalmente iguales, como veremos más adelante. En la siguiente sección, utilizaremos la noción de equivalencia por definición con frecuencia.

\subsubsection{Jerarquía de universos}

Puesto que en la teoría de tipos cada elemento tiene un tipo, también el tipo \code{Type} tiene un tipo asociado: el tipo \code{Type 1}. A su vez, \code{Type 1} tiene tipo \code{Type 2} y, en general, \code{Type n} tiene tipo \code{Type n+1} para cada $n$, formando una jerarquía numerable de tipos que llamaremos \textbf{universos}.

Esta jerarquía es no cumulativa, lo que significa que si \code{A : Type n}, no se asume en general que \code{A : Type (n+1)}. Esta propiedad evita que ocurran conversiones implítias y facilita la inferencia de tipos de Lean. Sin embargo, en la práctica Lean se encarga de realizar ciertas conversiones de manera automática, por lo que rara vez es necesario trabajar explícitamente con los universos.

\subsubsection{Tipos inductivos}

En Lean, la gran mayoría de tipos son instancias de una familia de tipos conocidos como \textbf{tipos inductivos}. Un tipo inductivo es una estructura formada por una lista finita de constructores, cada uno con su tipo correspondiente. Cada constructor describe una forma válida de construir un término de este nuevo tipo.

En Lean, definimos un tipo inductivo utilizando la palabra clave \bluecode{inductive}\footnote{Aunque en Lean los tipos inductivos se introducen como una construcción primitiva del lenguaje, pueden definirse de manera equivalente sólo en términos de tipos dependientes. Esta reducción se explora formalmente en \cite{carneiro2019type}.}.

\begin{lstlisting}
  inductive Foo where
    | constructor₁ : ... → Foo
    | constructor₂ : ... → Foo
    ...
    | constructorₙ : ... → Foo
\end{lstlisting}

Un ejemplo clásico de definición inductiva es el conjunto de los números naturales, $\mathbb{N}$. En Lean, podríamos describir el tipo \code{Nat} de los números naturales como

\begin{lstlisting}
  inductive Nat where
    | zero : Nat
    | succ : Nat → Nat
\end{lstlisting}

Internamente, la declaración \bluecode{inductive} genera automáticamente una colección de axiomas que definen el tipo:

\begin{itemize}
  \item Una constante, \code{Nat}, que representa el nuevo tipo.
  \item Una serie de reglas de introducción o constructores, que indican las posibles formas de construir términos del nuevo tipo. 
  \item Una regla de eliminación, \code{Nat.rec}, que indica la forma de \quotes{usar} un término de este tipo\footnote{El comando \bluecode{\#print} muestra la definición completa del objeto, a diferencia de \bluecode{\#check}, que solo muestra su tipo.}.
  \begin{lstlisting}
  #print Nat.rec
      -- recursor Nat.rec.{u}  :  {motive : ℕ → Sort u} → motive Nat.zero → ((n : ℕ) → motive n → motive n.succ) → (t : ℕ) → motive t\end{lstlisting}\end{itemize}

Es decir, \bluecode{inductive} puede verse como \textit{azúcar sintáctico} que genera automáticamente el siguiente código en Lean\footnote{Estudiaremos el comando \bluecode{axiom} en detalle más adelante.}:

\begin{lstlisting}
  axiom (Nat : Type)
  axiom (zero : Nat)
  axiom (succ : Nat → Nat)
  axiom (Nat.rec : {motive : Nat → Sort u} → motive Nat.zero →
    ((n : Nat) → motive n → motive Nat.succ n) → (t : Nat) → motive t)
\end{lstlisting}

Este último objeto, \code{Nat.rec}, codifica el principio de inducción sobre los naturales\footnote{\code{Nat.rec} es un tipo que depende de \code{motive}, que es una propiedad cualquiera sobre los naturales. \code{Nat.rec} nos dice que si se cumple \code{motive} para \code{Nat.zero} (\code{motive Nat.zero}), entonces si para cada \code{n} (\code{n : Nat}) que cumpla \code{motive} (\code{motive n}) se tiene que \code{n+1} cumple \code{motive} (\code{motive Nat.succ n}), entonces se cumple \code{motive} para cualquier \code{n} (\code{(t : Nat) → motive t}).}. Este principio se utiliza implícitamente en muchas definiciones por casos, como por ejemplo:

\begin{lstlisting}
  def add (m n : Nat) : Nat :=
    match n with
    | Nat.zero   => m
    | Nat.succ n => Nat.succ (add m n)
\end{lstlisting}

\newpage

En esta definición, utilizamos la expresión \code{match n with} para distinguir los dos posibles casos de un número natural: \code{zero} y \code{succ n}. Internamente, Lean compila esta expresión como una aplicación de \code{Nat.rec}. Veremos más adelante cómo este principio de inducción puede utilizarse no solo para definir funciones, sino también para probar propiedades sobre todos los términos de un tipo inductivo.

Finalmente, mediante los tipos inductivos es posible definir los conectores lógicos (negación, conjunción, disyunción e implicación). Esto constituye otra gran diferencia entre la teoría de conjuntos y el cálculo de construcciones inductivas. Para utilizar la teoría de conjuntos, es necesario haber desarrollado previamente la lógica (de primer orden). De esta manera, las demostraciones formales no constituyen objetos matemáticos, sino que viven exclusivamente en el plano metateórico.

En el cálculo de construcciones inductivas, en cambio, la lógica se expresa dentro de la misma teoría, y las demostraciones son objetos matemáticos que viven dentro de ella.

\newpage

\subsubsection{Las demostraciones como objeto matemático}

Las proposiciones, como cualquier otro objeto en esta teoría, son términos con un tipo asociado. En Lean, este tipo recibe el nombre de \code{Prop}.

\begin{lstlisting}
  #check Prop    -- Prop : Type
  variable (P : Prop)
  #check P    -- P : Prop
  #print True    -- inductive True : Prop
  #check ¬ P    -- ¬ P : Prop
\end{lstlisting}

En Lean, intepretamos los objetos de tipo \code{Prop} como tipos en sí mismos. En particular, una proposición \code{p : Prop} es el tipo de las demostraciones de \code{p}. Por tanto, una expresión de la forma \code{h : p} quiere decir que \code{h} es una demostración de \code{p}. Tiene entonces sentido decir que una proposición \code{p} es verdadera si podemos construir término de tipo \code{p}.

\begin{lstlisting}
  variable (p : Prop)
  variable (h : p)
  #check h    -- h : p
\end{lstlisting}

Esto, junto con la teoría de tipos dependientes, nos proporciona una forma de definir cualquier resultado matemático: por ejemplo, \quotes{ser par} es una propiedad que depende de un número natural $n$, por lo que podríamos describirlo mediante \code{es\_par : $\mathbb{N} \to$ Prop}. Para cada \code{n} natural, obtenemos un término de tipo \code{Prop}.

\begin{lstlisting}
  def es_par : ℕ → Prop := ...
  #check es_par    -- es_par : ℕ → Prop
  #check es_par 3    -- es_par 3 : Prop
\end{lstlisting}

En este caso, un término de tipo \code{es\_par n} será una prueba de que \code{n} es par.

Además, si \code{p : Prop} es una proposición, Lean reconoce cualesquiera dos elementos de tipo \code{p} (\code{h1 h2 : p}) como iguales por definición: no importa qué prueba concreta tengamos, sólo importa su existencia. Esto se conoce como \quotes{irrelevacia de las demostraciones} (\textit{proof irrelevance}).

Esta propiedad tiene ventajas prácticas. Por ejemplo, si demostramos una existencia (una proposición del estilo $\exists x, P(x)$) de dos maneras distintas utilizando dos valores diferentes, Lean identificará ambas pruebas, por lo que al extraer de $\exists x, P(x)$ un valor $x$ con $P(x)$, este valor será independiente de la demostración utilizada. Sin embargo, esto también tiene la desventaja de que este tipo de pruebas no son constructivas: no es posible recuperar exactamente el valor que utilizamos para completar la demostración.

También por esta propiedad, dadas dos proposiciones \code{p q : Prop}, podemos identificar los términos de tipo \code{Implies p q} con los términos de tipo \code{p $\to$ q}; si \code{h : Implies p q}, entonces \code{h} es una prueba de que \code{p} implica \code{q}, y por tanto podemos verlo como una función que, dada una prueba de \code{p}, devuelve una prueba de \code{q}. El conector \code{Implies} es por tanto redundante, y en lo que sigue utilizaremos sólo la expresión \code{$\to$}.

En resumen, para poder expresar un resultado matemático en este lenguaje, tenemos que escribir un término de la forma \code{p : Prop}. Para probar que el resultado es cierto, debemos construir un término \code{h : p}. El trabajo de Lean como asistente de demostración es verificar que el término \code{h} está bien construido y tiene el tipo correcto.


\subsection{¿Por qué fiarnos de Lean?}

Ahora que hemos descrito la manera en la que un resultado se considera demostrado en Lean, tiene sentido hacerse la pregunta: ¿por qué deberíamos fiarnos de la inferencia de tipos de Lean? ¿Qué garantías tenemos de que las demostraciones que Lean acepta, son realmente correctas? 

Como hemos señalado, demostrar un resultado en Lean consiste en construir correctamente un término que tiene un determinado tipo. Este proceso es análogo al de verificar programas: se trata de comprobar que un término está bien formado (siguiendo unas reglas concretas) y satisface una especificación dada, expresada como un tipo. Esta tarea recae sobre el núcleo (o \textit{kernel}) de Lean, un pequeño programa que contiene la implementación mínima de la lógica interna de Lean.

El resto de componentes de Lean con el que interactuamos para construir demostraciones (como por ejemplo las tácticas que veremos después) devuelven construcciones expresadas en el lenguaje del kernel de Lean \cite{bailey2024type}. Esto quiere decir que confiar en Lean realmente se reduce a confiar en su kernel\footnote{Esta idea se conoce como \textit{criterio de de Bruijn}, que propone que un verificador formal debe producir sus pruebas en el lenguaje de un núcleo pequeño, incluso aunque utilicen otros métodos más complicados para construir dichas pruebas a priori \cite{bailey2024type}.}.

Ahora, ¿por qué nos fiamos del kernel de Lean? Gracias a que el kernel es pequeño y está aislado del resto del sistema, es posible escribir implementaciones independientes del mismo que verifiquen de manera autónoma las demostraciones aceptadas por Lean. Lean permite exportar estas demostraciones en un formato intermedio que contiene toda la información necesaria para reconstruirlas y validarlas externamente. Además, puesto que este formato modular, es posible validar solo ciertos aspectos concretos del kernel \cite{bailey2024type}. Por ejemplo, en \cite{carneiro2024lean4lean}, Carneiro describe una nueva implementación externa del verificador de tipos de Lean 4, escrita en el propio lenguaje Lean y capaz de verificar toda la biblioteca de \textit{mathlib}.



\subsection{Demostraciones en Lean}

Hasta ahora, hemos explorado la teoría de tipos dependientes sobre la que se construye Lean, así como los fundamentos que garantizan la corrección de sus demostraciones. Pasamos por tanto a un enfoque más práctico: ¿cómo escribimos matemáticas en Lean?

Recordemos que formalizar un resultado en Lean no consiste solo en escribir su enunciado, sino también en construir una demostración paso a paso, sin omiciones y con total precisión. Aquí, nunca nos basta con escribir "trivial" cuando creamos que algo ya deberíamos poder saberlo: necesitamos convencer al sistema de que cada paso es válido.

Esta sección está dedicada a aprender a escribir demostraciones en Lean. Veremos cómo introducir nuevos objetos en nuestros contexto, como enunciar proposiciones y cómo construir demostraciones interactuando con Lean. También presentaremos algunas herramientas de automatización y métodos para poder apoyarnos en la librería de Mathlib.

\subsubsection{Axiomas, definiciones y variables}

Antes de escribir demostraciones en cualquier sistema formal, necesitamos describir el \textbf{contexto} en el que trabajamos: el conjunto de objetos e hipótesis disponibles en un momento dado. Este contexto es dinámico y se va ampliando a medida que introducimos nuevos elementos.

En Lean ocurre exactamente lo mismo. El sistema mantiene y actualiza este contexto constantemente para comprobar que cada expresión está bien formada y tiene el tipo esperado.

Podemos introducir nueva información en el contexto de distintas formas. Distinguimos entre axiomas, definiciones y variables, cada una con una función lógica distinta en el sistema.

\begin{itemize}
  \item \textbf{Axiomas}\footnote{En Lean 3, a este tipo de declaraciones se les llamaba \textit{constantes} y utilizaban el comando \bluecode{constant}.}
\end{itemize}

Permiten introducir hipótesis que se asumen sin demostración. En particular, escribir que "x es de tipo X" es también una hipótesis, por lo que los axiomas pueden utilizarse para introducir nuevos objetos\footnote{En este sentido decíamos que definir un tipo inductivo es análogo a escribir una colección de axiomas. \code{inductive Nat} se puede ver como una versión extructurada de \code{axiom Nat : Type}, \code{axiom zero : Nat}, \code{axiom succ : Nat to Nat}, etc.}. Por ejemplo:

\begin{lstlisting}
  axiom P : Prop
  axiom h : P → P
\end{lstlisting}

Estamos declaranto una proposicion $P$ y una prueba de que $P$ implica $P$.

\begin{lstlisting}
  axiom n : ℕ
  axiom hn : n > 2
\end{lstlisting}

Aquí estamos suponiendo que $n$ es un número natural mayor que $2$.

Así, los axiomas nos permiten fijar hechos en el contexto que queremos asumir como válidos a lo largo de nuestras demostraciones.


\begin{itemize}
  \item \textbf{Definiciones}
\end{itemize}

Introducen objetos nuevos a partir de otros ya conocidos. A diferencia de los axiomas, no  basta con indicar el tipo del nuevo objeto, sino que también hay que dar su construcción. Por ejemplo:

\begin{lstlisting}
  def f : ℕ → ℕ := fun n ↦ 2 * n
  def n : ℕ := 3
  def es_par : ℕ → Prop := fun n ↦ ∃ m, n = f m
\end{lstlisting}

Además, cuando el tipo puede inferirse a partir de la construcción, no es necesario indicarlo explícitamente:

\begin{lstlisting}
  def n := 3
  #check n    -- n : ℕ
\end{lstlisting}

\begin{itemize}
  \item \textbf{Variables}
\end{itemize}

Al contrario de lo que estamos acostumbrados, definir una variable en Lean no significa asignarle un valor arbitrario. En su lugar, lo que se introduce es un contexto universal: si $x$ es una variable, siempre que $x$ aparezca de forma libre, Lean interpretará que lo que sigue está cuantificado universalmente respecto a $x$. Por ejemplo\footnote{Las variables, a diferencia de los axiomas y las definiciones, se escriben entre paréntesis. Lo mismo ocurre con los argumentos que toman las proposiciones, como veremos más adelante. Esto está relacionado con la correspondencia de Curry–Howard: declarar una variable equivale a abstraer sobre ella, y por tanto a cuantificar universalmente(?).}:

\begin{lstlisting}
  variable (x : ℕ)
  axiom hx : x ≥ 0
  #print hx    -- axiom hx : ∀ (x : ℕ), x ≥ 0
\end{lstlisting}

\subsubsection{Proposiciones}

Además de introducir objetos, también queremos enunciar y demostrar proposiciones. En Lean, esto se hace del mismo modo que en otros sistemas formales: primero escribimos los resultados (como lemas o teoremas) formalmente, y después proporcionamos una demostración.

Como ya hemos visto, una proposición en Lean es un término de tipo \code{Prop}, y una demostración de \code{p : Prop} es simplemente un término de tipo \code{p}. Por tanto, demostrar una proposición no es diferente de definir un objeto; podemos utilizar \bluecode{def} para escribir resultados matemáticos. Por ejemplo:

\begin{lstlisting}
  def mi_prop : 1 > 0 := ...
\end{lstlisting}

Aquí estamos diciendo que \code{mi\_prop} es un objeto de tipo \code{1 > ~0}. Si en el lugar de \code{...} proporcionamos un término de tipo \code{1 > ~0}, habremos demostrado \code{mi\_prop}.

Sin embargo, para mayor claridad y estructura, Lean proporciona los comandos \bluecode{lemma} y \bluecode{theorem}. Ambos funcionan exactamente igual que \bluecode{def} y son intercambiables entre sí, pero facilitan la lectura del código indicando qué objetos son resultados matemáticos, y la jerarquía de importancia entre ellos. La sintaxis es la misma:

\begin{lstlisting}
  lemma my_lemma : 1 > 0 := ...
  theorem commutative_sum (a b : ℕ) : a + b = b + a := ...
\end{lstlisting}

Existe también el comando \bluecode{example}, que sirve para escribir demostraciones sin la necesidad de nombrar el resultado:

\begin{lstlisting}
  example (a b : ℕ) : a * b = b * a := ...
\end{lstlisting}

Este tipo de expresiones no amplían el contexto ni definen nuevos objetos; son simplemente comprobaciones locales. Pero veremos que nos pueden ser útiles en ciertas ocasiones.


\subsubsection{Demostraciones: el modo táctico}

\subsubsection{Herramientas de automatización}

\subsubsection{Utilizar Mathlib}


\newpage

\section{Espacios topológicos en Lean}

Explicar algunos ejemplos de definiciones y demostraciones, no a modo de explicación completa de los prerrequisitos de topoogía sino para tener un primer acercamiento sencillo a la topología en Lean.

\subsection{Espacios topolǵicos normales}

Introducción : ¿por qué son interesantes?

\begin{definition}
  Sea $X$ un espacio topológico. $X$ es \emph{normal} si para cada par de cerrados disjuntos $C, D \subseteq X$ existen abiertos disjuntos $U$ y $V$ en $X$ tales  que separan $C$ y $D$, es decir, $C \subseteq U$ y $D \subseteq V$ \textnormal{(véase \cite[p. 99]{willard2012general})}.
\end{definition}

En Lean, escribimos esta definición de la siguiente forma.

\begin{lstlisting}
  def NormalTopoSpace {X : Type} (T : TopologicalSpace X) : Prop :=
    ∀ C : Set X, ∀ D : Set X,
    IsClosed C → IsClosed D → C ∩ D = ∅ →
    ∃ U : Set X, ∃ V : Set X,
      IsOpen U ∧
      IsOpen V ∧
      C ⊆ U ∧
      D ⊆ V ∧
      U ∩ V = ∅
\end{lstlisting}

Ahora queremos dar una caracterización para este tipo de espacios, que nos facilitará el trabajo más adelante.

\begin{proposition}[Caracterización de la normalidad]
  Sea $X$ un espacio topológico. $X$ es normal si y sólo si para cada abierto $U$ y cada cerrado $C$ de $X$ tales que $C \subseteq U$, existe un abierto $V \subset X$ de forma que $C \subseteq V \subseteq \overline{V} \subseteq U$.
\end{proposition}

En Lean, escribimos:

\begin{lstlisting}
  lemma characterization_of_normal {X : Type}
    (T : TopologicalSpace X) :
    NormalTopoSpace T ↔
      ∀ U : Set X, ∀ C : Set X, IsOpen U → IsClosed C → C ⊆ U →
      ∃ V : Set X, IsOpen V ∧ C ⊆ V ∧ (Closure V) ⊆ U := by sorry
\end{lstlisting}

\begin{proof}
  Veamos primero una implicación, y luego la otra (utilizamos \bluecode{constructor}).

  ($\implies$) Supongamos que $X$ es un espacio normal (\code{hT}) y sean $U$ un abierto (\code{hU}) y $C$ un cerrado (\code{hC}) tales que $C \subseteq U$ (\code{hCU}).

\begin{lstlisting}
    intro hT U C hU hC hCU
\end{lstlisting}
  
  Puesto que $X$ es normal, por la definición, para $C$ y $U^c$ cerrados en $X$ obtenemos $V_1$ y $V_2$ abiertos (\code{V1\_open}, \code{V2\_open}) disjuntos (\code{hV}) tales que $C \subseteq V_1$ (\code{hCV}) y $U^c \subseteq V_2$ (\code{hUV}).

\begin{lstlisting}
  obtain ⟨V1, V2, V1_open, V2_open, hCV, hUV, hV⟩ :=
    hT C Uᶜ
    hC
    (by exact isClosed_compl_iff.mpr hU)
    (by rw [ABdisjoint_iff_AsubsBc, compl_compl]; exact hCU)
\end{lstlisting}

  Por supuesto, en Lean tenemos que especificar por qué $U^c$ es cerrado y por qué $U^c \subseteq V_2$. Ahora tenemos una hipótesis de la forma

\begin{lstlisting}
  h : IsOpen V1 ∧ IsOpen V2 ∧ C ⊆ V1 ∧ Uᶜ ⊆ V2 ∧ V1 ∩ V2 = ∅
\end{lstlisting}
  
  Tomamos como $V$ el $V_1$ obtenido de esta forma,

\begin{lstlisting}
    use V1
\end{lstlisting}

  Queremos ver que satisface las condiciones que le pedimos:

\begin{lstlisting}
  ⊢ IsOpen V1 ∧ C ⊆ V1 ∧ Closure V1 ⊆ U
\end{lstlisting}
  
  Cómo tiene que cumplir tres condiciones, tendremos que utilizar \bluecode{constructor} varias veces. En primer lugar, $V_1$ es abierto por construcción. Además, $C \subseteq V_1$ también por construcción.

\begin{lstlisting}
    constructor
    · exact V1_open
    constructor
    · exact hCV
\end{lstlisting}

  Ahora queda demostrar que $\overline{V_1} \subseteq U$. Por un lado, tenemos que $V_1$ y $V_2$ son disjuntos, luego, en particular, como $V_2$ es abierto, se tiene que $\overline{V_1}$ y $V_2$ son disjuntos.

\begin{lstlisting}
    · apply disjointU_V_then_disjointClosureU_V V2_open at hV
      apply Set.disjoint_iff_inter_eq_empty.mpr at hV -- usamos la propiedad Disjoint de Lean
\end{lstlisting}

  Por otro lado, tenemos que $\overline{V_1} \subseteq U$ $\iff$ $V_1$ y $U^c$ son disjuntos. Basta ver que lo son utilizando lo anterior, sabiendo que $U^c \subseteq V_2$.

\begin{lstlisting}
      apply Set.disjoint_compl_right_iff_subset.mp
      exact Set.disjoint_of_subset_right hUV hV
\end{lstlisting}

  ($\Longleftarrow$) Procedemos de manera similar. Sean $C_1$, $C_2$ cerrados (\code{C1\_closed}, \code{C2\_closed}) disjuntos (\code{hC}). Podemos aplicar la hipótesis (\code{h}) al abierto $C_1^c$ y al cerrado $C_2$ para obtener obtener un abierto $V$ (\code{V\_open}) de manera que $C_2 \subseteq V \subseteq \overline{V} \subseteq C_1^c$ (\code{hV}).

\begin{lstlisting}
    intro h C1 C2 C1_closed C2_closed hC
    obtain ⟨V, V_open, hV⟩ :=
      h C1ᶜ C2
      (by exact IsClosed.isOpen_compl)
      C2_closed
      (by rw [← ABdisjoint_iff_AsubsBc, Set.inter_comm C2 C1]; exact hC)
\end{lstlisting}

  Ahora tomamos los abiertos $U_1 = \overline{V}^c$ y $U_2 = V$. Queremos ver que cumplen la condición de normalidad para $C_1$ y $C_2$.
  
\begin{lstlisting}
  IsOpen (Closure V)ᶜ ∧ IsOpen V ∧ C1 ⊆ (Closure V)ᶜ ∧ C2 ⊆ V ∧ (Closure V)ᶜ ∩ V = ∅
\end{lstlisting}
  
  En efecto, ambos son abiertos ($\overline{V}^c$ por ser el complementario de una clausura y $V$ por construcción).

\begin{lstlisting}
    constructor
    · simp
      exact closure_is_closed V
    constructor
    · exact V_open
\end{lstlisting}

  Además, $C_1 \subseteq \overline{V}^c$ es equivalente a $\overline{V} \subseteq C_1^c$, que es cierto por construcción de $V$, igual que $C_2 \subseteq V$.
  
\begin{lstlisting}
    constructor
    · apply Set.subset_compl_comm.mp
      exact hV.right
    constructor
    · exact hV.left
\end{lstlisting}

  Por último, se tiene

  $$
  \overline{V}^c \cap V = \emptyset \iff V \cap \overline{V}^c = \emptyset \iff
  V \subseteq \overline{V}^{cc} \iff V \subseteq \overline{V},
  $$

  que es cierto por las propiedades de la adherencia.

\begin{lstlisting}
    · rw [Set.inter_comm]
      rw [ABdisjoint_iff_AsubsBc]
      simp
      exact set_inside_closure V
\end{lstlisting}



  





  

  




\end{proof}



\section{El Lema de Urysohn}

Introducción:

Definición: espacio normal

Lema (de Urysohn):

Esta demostración es relativamente complicada en papel, pero todavía lo es más cuando intentamos completarla en Lean. Por claridad, dividimos la demostración en varios pasos.

La demostración en Lean empieza utilizando la táctica \bluecode{constructor}, que nos divide el objetivo en dos, uno para cada implicación. Nos centraremos primero en la segunda, que es la más sencilla.

\subsection{El recíproco}





Queremos 

Demostración


\subsection{Numerar los racionales}

Los racionales son denumerables, es decir existe una biyección entre $\nat$ y $\rat$.

En particular, existe una función $f : \nat \to Q$ donde $Q = \rat \cap [0, 1]$, de forma que

\begin{enumerate}
  \item $f$ es biyectiva
  \item $f(0) = 1$
  \item $f(1) = 0$
\end{enumerate}

A partir de ahora llamarmeos $f$ a esta función.

Demostración:

Demostración en Lean: [poner solo las partes importantes?]

\subsection{Una parte}

Sea $n \in \nat$ con $n > 1$. Como $$P_n = \{1, 2, \dots, n-1\}$$ es un conjunto finito y $f$ es sobreyectiva, existen $r$ y $s$ en $P_n$ (es decir, $r < n$ y $s < n$) tales que

\begin{equation} \label{cond_rs}
  f(r) < f(n) < f(s)
\end{equation}

y, además, estas son las mejores elecciones, es decir

\begin{enumerate}
  \item Si $m < n$ es tal que $f(m) < f(n)$, entonces $f(m) \leq f(r)$
  \item Si $m < n$ es tal que $f(n) < f(m)$, entonces $f(s) \leq f(m)$
\end{enumerate}

Además, como $f$ es inyectiva, estas elecciones son únicas.

Para cada $n > 1$, consideramos las funciones $r : \nat \to \nat$ y $s : \nat \to \nat$ que nos dan precisamente estos números $r$ y $n$.

--

Supongamos que hemos encontrado una función $G : \nat \to \mathcal{P}(X)$ que satisface las siguientes propiedades

\begin{enumerate}
  \item $G(0) = X \backslash C_2$
  \item $G(1) = V$ tal que $C_1 \subseteq V \subseteq \overline{V} \subseteq X \backslash C_2$
  \item Para cada $n \in \nat $, $G(n)$ es abierto en $X$
  \item Para cada $n \in \nat$, si $n>1$ entonces \begin{equation} \label{cond_Grs} \overline{G(r(n))} \subseteq G(n) \subseteq \overline{G(n)} \subseteq G(s(n)) \end{equation}
\end{enumerate}

Queremos probar que, en este caso, $G$ también cumple la siguiente propiedad:

\begin{equation} \label{cond_G}
  \forall n, m \in \nat, f(n) < f(m) \implies \overline{G(n)} \subseteq G(m)
\end{equation}


\begin{proof}

Sean $n, m \in \nat$ con $f(n) < f(m)$

Para empezar, como $f(n) < f(m)$, no puede ser $n=0$ ni $m=1$:

\begin{itemize}
  \item Si fuera $n = 0$, entonces $f(n) = 1$ y tendríamos $1 < f(m)$, pero $f$ toma valores en $[0, 1]$.
  \item Si fuera $m = 1$, entonces $f(m) = 0$ y tendríamos $f(n) < 0$, pero $f$ toma valores en $[0, 1]$.
\end{itemize}

Además, $n \neq m$ por ser $f$ inyectiva. Dividimos en los siguientes casos.

\textit{Caso 1.} $n = 1, m = 0$

Trivialmente por hipótesis (prop. 2 de G)

\textit{Caso 2.} $n > 1, m = 0$, por inducción completa sobre $n$

Sea $n>1$ arbitrario y supongamos, por inducción, que para cada $k < n$ con $k > 1$ se tiene $\overline{G(k)} \subseteq G(m)$.

Hay dos posibilidades: o bien $s(n)=0$ o bien $s(n)>1$. En el caso de que $s(n)=0$ es sencillo: tenemos $m=0=s(n)$, por tanto el objetivo pasa a ser $\overline{G(n)} \subseteq G(s(n))$, que es cierto por las propiedades de G.

Supongamos por tanto que $s(n)>1$. Entonces podemos aplicar la hipótesis de inducción a $k=s(n)>1$, y obtenemos que $\overline{G(s(n))} \subseteq G(m)$. Pero, por las propiedades de G,  $\overline{G(n)} \subseteq G(s(n))$. Obtenemos, por las propiedades de la adherencia,

$$\overline{G(n)} \subseteq G(s(n)) \subseteq \overline{G(s(n))} \subseteq G(m)$$

\textit{Caso 3.} $n = 1, m > 1$, por inducción completa sobre $m$

Es simétrico al anterior. Sea $m>1$ arbitrario y supongamos, por inducción, que para cada $l < m$ con $l > 1$ se tiene $\overline{G(n)} \subseteq G(l)$.

Hay dos posibilidades: o bien $r(m)=1$ o bien $r(m)>1$. En el caso de que $r(m)=1$ es sencillo: tenemos $n=1=r(m)$, por tanto el objetivo pasa a ser $\overline{G(r(m))} \subseteq G(m)$, que es cierto por las propiedades de G.

Supongamos por tanto que $r(m)>1$. Entonces podemos aplicar la hipótesis de inducción a $l=r(m)>1$, y obtenemos que $\overline{G(n)} \subseteq G(r(m))$. Pero, por las propiedades de G,  $\overline{G(r(m))} \subseteq G(m)$. Obtenemos, por las propiedades de la adherencia,

$$ \overline{G(n)} \subseteq G(r(m)) \subseteq \overline{G(r(m))} \subseteq G(m) $$

\textit{Caso 4.} $n > 1, m > 1$. Dividimos en dos casos adiccionales:

\textit{Caso 4.1.} $m < n$

Por inducción sobre $n$. Sea $n>m>1$ tal que $f(n) < f(m)$ y supongamos, por inducción, que para cada $k < n$ con $k>m$ y $f(k) < f(m)$ se tiene 

Sabemos que $m < n$ y que $f(n) < f(m)$. Por tanto, podemos aplicar las propiedades de $s$ sobre $n$ ($f(n) < f(s(n))$ es la mejor elección) y obtenemos que $f(s(n)) \leq f(m)$.

Si $f(s(n)) = f(m)$, como $f$ es inyectiva, $s(n)=m$. Luego es trivial porque el objetivo pasa a ser $\overline{G(n)} \subseteq G(s(n))$.

Supongamos que $f(s(n)) < f(m)$.

\textit{Caso 4.2.} $m < n$


Supongamos primero que $n = 1$ y $m = 0$. Entonces conocemos los valores de $G(n)$ y $G(m)$, y la expresión \refpep{cond_G} que queremos probar pasa a ser

$$
  \overline{V} \subseteq X \backslash C_2
$$

que es cierto por hipótesis.

Supongamos ahora que $n, m >1$. Entonces ambas satisfacen \refpep{cond_Grs}. Vamos a probar

\begin{equation} \label{cond_G_inductive}
  \forall n, m > 1, f(n) < f(m) \implies \overline{G(n)} \subseteq G(m)
\end{equation}

Nota:
En un caso extremadamente explicativo (pero para que fuera consistente en cierta manera con la demostración en Lean) quizás podría escribir que esta condición es equivalente a esta otra, sobre la que se puede aplicar inducción completa "normal":

$$
  \forall n, m \in \nat, f(n+2) < f(m+2) \implies \overline{G(n+2)} \subseteq G(m+2)
$$


Por inducción completa sobre $n$ y $m$.

Inducción sobre $n$.

\begin{itemize}
  \item \textit{Caso base} ($n = 2$).
\end{itemize}
  
Como $n=2$, y se tiene $r(n) < n$ y $s(n) < n$, podemos asegurar que $r(n), r(s) \in \{0, 1\}$.

En particular, para que se cumpla \refpep{cond_rs}, necesariamente tiene que ser $$0 = f(1) < f(2) < f(0) = 1$$ y por tanto $r(n) = 1$ y $s(n) = 0.$

Sea entonces un $m > 1$ fijo pero arbitrario. Sabemos que $m \neq 2$ por ser $f$ inyectiva.

Inducción sobre $m$

\begin{itemize}
  \setlength{\itemindent}{2em}
  \item[$\circ$] \textit{Caso base} ($n = 2, m= 3$)
\end{itemize}

Como $f(n) < f(m)$, se tiene $$0 < f(1) < f(2) < f(3) < f(0) = 1.$$ Por tanto, $r(m) = 2 = n$ y $s(m) = 0$. De \refpep{cond_Grs}, se obtiene:

$$
\overline{G(n)} = \overline{G(r(m))} \subseteq G(m),
$$

como queríamos.

\begin{itemize}
  \setlength{\itemindent}{2em}
  \item[$\circ$] \textit{Caso recursivo} ($n = 2, m>3$)
\end{itemize}

Hipótesis de inducción:

\begin{equation} \label{cond_G_ind_m}
  \forall l < m \text{ con } l > 1, f(2) < f(l) \implies \overline{G(2)} \subseteq G(l)
\end{equation}

Veamos primero que se tiene que dar $r(m) > 1$.

\begin{itemize}
  \item $r(m) \neq 0$. Si fuera $r(m) = 0$ tendríamos $1 = f(0) < f(m)$, que es imposible.
  \item $r(m) \neq 1$. Si fuera $r(m) = 1$, como $f(n) < f(m)$ y $r(m)$ es la mejor elección, tendríamos $f(n) \leq f(r(m)) = f(1) = 0$. Como $n=2\neq 1$, entonces $f(n) < 0$, que es imposible.
\end{itemize}


Luego $r(m)> 1$ y podemos aplicar \refpep{cond_G_ind_m} a $l=r(m)<m$, obteniendo $$\overline{G(2)} \subseteq G(r(m)).$$

Por otro lado, por \refpep{cond_Grs}, sabemos que $$\overline{G(r(m))} \subseteq G(m).$$ Mediante las propiedades de la adherencia, unimos las expresiones

$$
\overline{G(2)} \subseteq G(r(m)) \subseteq \overline{G(r(m))} \subseteq G(m),
$$

finalizando por tanto la inducción sobre $m$.

\begin{itemize}
  \item \textit{Caso recursivo} ($n > 2$, $m>1$ es fijo pero arbitrario)
\end{itemize}

Hipótesis de inducción:
\begin{equation} \label{cond_G_ind_n}
  \forall k < n \text{ con } k > 1, f(k) < f(m) \implies \overline{G(k)} \subseteq G(m)
\end{equation}

Tenemos que diferenciar dos casos: $s(n) = 0$ y $s(n) > 1$ (no puede ser $s(n) = 1$ porque en ese caso tendríamos $f(n) < f(s(n)) = f(1) = 0$, que es imposible).

Supongamos primero que $s(n) = 0$. Entonces, como $f(n) < f(m)$ y $s(n)$ es la mejor elección, tenemos que $f(s(n)) \leq f(m)$. Sin embargo, en realidad no puede darse $f(s(n)) < f(m)$, porque tendríamos $1 = f(0) = f(s(n)) < f(m)$, que es imposible. Luego en caso de que $s(n)=0$, necesariamente se tiene $f(s(n)) = f(m)$, y por inyectividad de $f$, $s(n) = m$. Entonces el resultado se sigue trivialmente de \refpep{cond_Grs} aplicado a $n>1$:

$$
  \overline{G(n)} \subseteq G(s(n)) = G(m).
$$

Si suponemos ahora que $s(n)>1$, podemos aplicar \refpep{cond_G_ind_n} a $k = s(n) < n$, obteniendo $$\overline{G(s(n))} \subseteq G(m).$$

Además, por \refpep{cond_Grs}, como $n > 1$, se tiene $$\overline{G(n)} \subseteq G(s(n)),$$ y, por las propiedades de la adherencia, podemos unir ambas expresiones $$\overline{G(n)} \subseteq G(s(n)) \subseteq \overline{G(s(n))} \subseteq G(m)$$ obteniendo el resultado que buscábamos.


\end{proof}

% Bibliografía

\bibliographystyle{myunsrt}
\bibliography{references.bib}

\end{document}
