\documentclass{article}

% Paquetes usados
\usepackage{graphicx} % Imágenes
\usepackage{amsmath} % Algunos símbolos matemáticos
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{array} % Matrices, tablas
\usepackage{xcolor} % Colores de texto
\usepackage{enumitem} % Listas con letras
\usepackage[spanish]{babel} % Español
\usepackage{url}
%LEAN
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{color}
\definecolor{keywordcolor}{rgb}{0.8, 0.1, 0.1}   % red
\definecolor{tacticcolor}{rgb}{0.0, 0.1, 0.9}    % blue
\definecolor{commentcolor}{rgb}{0.4, 0.4, 0.4}   % grey
\definecolor{symbolcolor}{rgb}{0.0, 0.1, 0.6}    % blue
\definecolor{sortcolor}{rgb}{0.1, 0.5, 0.1}      % green
\definecolor{attributecolor}{rgb}{0.7, 0.1, 0.1} % red
\definecolor{backgroundcolor}{rgb}{0.92, 0.92, 0.92} % light grey

% Distancias entre párrafos, quitar sangrías
\setlength{\parindent}{0pt}
\setlength{\parskip}{.8em}

% Espaciados entre palabras en el justificado.
\sloppy

% Título
\title{Formalización de las matemáticas con Lean. Un caso de estudio: Resultados de Topología General.}
\author{Pepa Montero Jimena}
\date{}

% Inline code
\usepackage{tikz}
\tikzset{%
    baseline,
    inner sep=2pt,
    minimum height=12pt,
    rounded corners=2pt  
}
\newcommand{\code}[1]{\mbox{% added this percent
    \ttfamily
    \tikz \node[anchor=base,fill=backgroundcolor]{#1};% added this percent
}}
\newcommand{\bluecode}[1]{\code{\textcolor{blue}{#1}}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\redcode}[1]{\code{\textcolor{red}{#1}}}

% Lean code
\def\lstlanguagefiles{lstlean.tex}
\lstset{language=lean, backgroundcolor=\color{backgroundcolor}} %default language  

% Spell checker settings
% spell-checker: disable

% Math commands
\newcommand{\nat}{\mathbb{N}}
\newcommand{\rat}{\mathbb{Q}}

% Other commands
\newcommand{\refpep}[1]{(\ref{#1})}
\newcommand{\quotes}[1]{``#1''}

% Theorem environments
\newtheorem{definition}{Definición}[section]
\newtheorem{proposition}{Proposición}[section]


\begin{document}

\maketitle

\section{Introducción}

Introducción al trabajo.

\newpage

\section{Lean Theorem Prover}

A medida que las matemáticas se vuelven más técnicas y especializadas, verificar con rigor las demostraciones formales es una tarea cada vez más costosa. Con la motivación de facilitarla, en las últimas décadas ha surgido un interés por la verificación computacional de teoremas, dando lugar al desarrollo de sistemas como Lean, Coq o Isabelle.

Dentro de este campo, distinguimos dos tipos de sistemas de verificación formal: interactivos (ITP), que proporcionan un entorno en el que usuario guía el proceso de la demostración paso a paso, centrándose en el aspecto de "verificación", y automáticos (ATP), que buscan completar demostraciones de manera completamente autónoma \cite[Sección~1]{avigad2024theorem}.

En este trabajo nos centraremos en el uso de \textbf{Lean Theorem Prover}, introducido en 2013 por Leonardo de Moura desde Microsoft Research. Se trata de un verificador cuyo objetivo es reducir la distancia entre demostraciones asistidas y automatizadas, combinando un lenguaje basado en la teoría de tipos dependientes con herramientas que permiten delegar subproblemas sencillos al sistema

Aunque aquí nos limitaremos a su uso como asistente de demostración, Lean es también un lenguaje de programación funcional completo, lo que ofrece amplias posibilidades de personalización y automatización al usuario \cite[Sección~1]{avigad2024theorem}.

En este sistema, es posible definir objetos matemáticos, especificar propiedades sobre ellos y demostrar que dichas propiedades se cumplen. Esta tarea se ve facilitada por \textit{Mathlib}, una extensa biblioteca de matemáticas formalizadas en Lean desarrollada colaborativamente por una comunidad activa y en constante crecimiento \cite{mathlib}.

Las demostraciones son verificadas automáticamente por el núcleo lógico de Lean, que garantiza su corrección mediante un sistema de tipos expresivo y riguroso. La fiabilidad de Lean como asistente de demostración reside precisamente en la simplicidad y robustez de este núcleo \cite{bailey2024type}.

En esta sección seguiremos principalmente el manual en línea \textit{Theorem Proving in Lean 4}~\cite{avigad2024theorem} que es una versión actualizada del libro \textit{Theorem Proving in Lean}~\cite{avigad2021theorem} publicado en 2021 para adaptarse a la nueva versión de Lean. A nivel teórico, no existe una gran diferencia entre los dos, por lo que ambas referencias son válidas para comprender los fundamentos que exponemos aquí.


\subsection{La teoría de tipos de Lean}

La teoría de conjuntos de Zermelo-Fraenkel con el axioma de elección (ZFC) es la base fundacional elegida para formalizar la mayoría de las matemáticas que conocemos. En este marco, todos los objetos matemáticos (números, funciones, estructuras algebraicas, etc.) pueden representarse como conjuntos, construidos a partir de unos pocos axiomas básicos.

Sin embargo, este sistema carece de una estructura interna diferenciada: todo objeto matemático, como un número, una función o incluso una colección de funciones son, en última instancia, conjuntos. Para lograr una representación más clara y diferenciada de los objetos matemáticos, Lean utiliza, en su lugar, un sistema basado en tipos. Además, este enfoque nos ofrece la posibilidad de establecer una correspondencia entre programas y demostraciones matemáticas, conocida como la correspondencia de Curry-Howard\footnote{La correspondencia de Curry-Howard establece una relación entre lógica y programación; permite entender como pueden ser equivalentes \quotes{demostrar una proposición} y \quotes{construir un término de cierto tipo}. Veremos qué quiere decir esto en la práctica más adelante, pero las ideas más profundas, que quedan fuera del alacance de este trabajo, se exponen detalladamente en \cite{sorensen2006lectures}.}.

En particular, Lean se fundamenta en el \textit{Cálculo de Construcciones Inductivas}, una extensión del cálculo de tipos dependientes que incorpora tipos inductivos y una jerarquía numerable no cumulativa de universos \cite{coquand1986calculus}. Aunque no es necesario entender este sistema para utilizar Lean como asistente de demostración, a continuación daremos una breve explicación de los conceptos fundamentales.

En esta sección, veremos varios fragmentos de código en Lean. Lean cuenta con un compilador interactivo que procesa cada línea cuando el cursor se encuentra sobre ella, mostrando el resultado por pantalla. A partir de ahora, los comentarios que acompañan al código reflejan la salida que Lean devuelve en cada línea. Los comentarios en Lean se escriben empezando con doble guión ($--$) y están en color gris.

\subsubsection{Teoría de tipos}

Empecemos por lo más básico: la teoría de tipos. Cambiamos el foco de \quotes{cada objeto es un conjunto }, propio de ZFC, a \quotes{cada objeto es un término con un tipo asociado}. Esto nos permite estructurar con mayor claridad los objetos matemáticos y sus relaciones.

Por ejemplo, $3$ es un término de tipo \quotes{natural} ($\mathbb{N}$), mientras que \quotes{true} es un término de tipo \quotes{booleano}. En Lean podemos comprobar el tipo de estas expresiones utilizando el comando \bluecode{\#check}\footnote{En Lean, podemos escribir $\mathbb{N}$ escribiendo \code{$\backslash$nat} en el editor y luego pulsando espacio. En general, escribiremos los símbolos matemáticos de esta forma. Una lista comprensiva con los símbolos utilizados en el proyecto y sus respectivos comandos se puede encontrar en (un anexo)}:

%to-do: me sale en 3 en negro
\begin{lstlisting}
  #check 3    -- 3 : ℕ 
  #check true   -- Bool.true : Bool
\end{lstlisting}

Como en este ejemplo, en Lean utilizamos el símbolo $:$ para describir la información sobre el tipado. Es decir, si $x$ es un término de tipo $X$, escribimos $x : X$.

Por otro lado, un tipo, como es $\mathbb{N}$, también es un término. Podemos comprobar su tipo:

\begin{lstlisting}
  #check ℕ    -- ℕ : Type
\end{lstlisting}

En Lean, los tipos tienen su propio tipo, que recibe el nombre de \code{Type}. Esto nos permite definir nuevos tipos. Podemos utilizar el comando \bluecode{variable} para definir objetos en nuestro código\footnote{Veremos este comando en detalle más adelante}.

\begin{lstlisting}
  variable (X : Type)
  #check X    -- X : Type
  variable (x : X)
  #check x    -- x : X
\end{lstlisting}

Ahora, podemos combinar distintos tipos para obtener tipos más complejos. Sean $X$ e $Y$ dos tipos. Podemos considerar el tipo $X \times Y$, que denota los pares formados por un elemento de $X$ y otro de $Y$. El tipo que más utilizaremos es $X \to Y$, que denota las funciones de $X$ en $Y$. Escribimos esto en Lean.

\begin{lstlisting}
  variable (X Y : Type)
  #check X × Y    -- X × Y : Type
  variable (x : X) (y : Y)
  #check (x, y)    -- (x, y) : X × Y
  
  #check X → Y    -- X → Y : Type
  variable (f : X → Y)
  #check f    -- f : X → Y
\end{lstlisting}

Por otro lado, a partir de la yuxtaposición de términos simples, podemos formar términos más complejos. En Lean, las reglas de tipado dictan el tipo de estos nuevos términos obtenidos. Por ejemplo, si $x$ es de tipo $X$ y $f$ es de tipo $A \to B$, como en el ejemplo anterior, entonces $f x$ tiene tipo $B$. En efecto:

\begin{lstlisting}
  #check f x    -- f x : Y
\end{lstlisting}

La capacidad de Lean para identificar el tipo de un término sin necesidad de que el usuario lo especifique se conoce como \textbf{inferencia de tipos}. Como veremos más adelante, este proceso ocurre de manera automática en su núcleo y es el aspecto crucial de la verificación de demostraciones.

\subsubsection{Teoría de tipos dependientes}

Para poder expresar los distintos objetos matemáticos en esta teoría, es importante que un tipo no sea necesariamente estático, sino que pueda depender de otros términos.

Por ejemplo, \code{Fin} es un tipo en Lean que describe los números naturales menores que otro número natural dado. Precisamente, no tiene sentido afirmar que un término tiene tipo \code{Fin}, porque \code{Fin} depende de este número dado: un término de tipo \code{$\mathbb{N}$}. En efecto,

\begin{lstlisting}
  #check Fin    -- Fin (n : ℕ) : Type
  #check Fin 5    -- Fin 5 : Type
\end{lstlisting}

Decimos que \code{Fin} es un tipo dependiente, porque depende del valor de n. Lean admite, por tanto, tipos dependientes en su teoría.

\subsubsection{Cálculo de Construcciones}

El Cálculo de Construcciones es una extensión del Cálculo Lambda con tipos \cite{coquand1986calculus}. El Cálculo Lambda, introducido por Alonzo Church en los años 1930, es un sistema formal en el que todos los términos se ven como funciones (o abstracciones) y se operan entre sí mediante aplicación de funciones (el uso de una función sobre un argumento) \cite{pierce2002types}. A pesar de su simplicidad, este sistema se ha convertido en la base formal de muchos lenguajes de programación modernos.

Por ejemplo, una función válida podría ser $n \mapsto 2n : \mathbb{N} \rightarrow \mathbb{N}$, que representa una función que, al ser aplicada a un número natural, devuelve el número multiplicado por dos.

En Lean, definimos funciones utilizando el comando \code{fun}\footnote{En la versión anterior de Lean, se utilizaba la notación \code{$\lambda$ n, 2 * n}, más similar a la del Cálculo Lambda, sin embargo en esta última versión se ha cambiado a \code{fun n $\mapsto$ 2 * n} para mejorar la legibilidad del código.}, por ejemplo\footnote{Estudiaremos el comando \bluecode{def} en detalle más adelante.}:

\begin{lstlisting}
  def f : ℕ → ℕ := fun n ↦ 2 * n
\end{lstlisting}

Además, se puede definir una reducción sobre este tipo de términos: el término formado por la anterior función aplicada a $3$, $(n \mapsto 2n)3$, se puede reducir a $2 \cdot 3$ por aplicación funcional, y luego a $6$ por definición de la multiplicación.

Podemos comprobar el resultado de esta reducción utilizando el comando \bluecode{\#eval}.

\begin{lstlisting}
  #eval f 3    -- 6
\end{lstlisting}

Diremos que dos términos que pueden reducirse de esta manera al mismo valor son \textbf{iguales por definición}. Lean trata términos que sean iguales por definición como literalmente iguales, como veremos más adelante. En la siguiente sección, utilizaremos la noción de equivalencia por definición con frecuencia.

\subsubsection{Jerarquía de universos}

Puesto que en la teoría de tipos cada elemento tiene un tipo, también el tipo \code{Type} tiene un tipo asociado: el tipo \code{Type 1}. A su vez, \code{Type 1} tiene tipo \code{Type 2} y, en general, \code{Type n} tiene tipo \code{Type n+1} para cada $n$, formando una jerarquía numerable de tipos que llamaremos \textbf{universos}.

Esta jerarquía es no cumulativa, lo que significa que si \code{A : Type n}, no se asume en general que \code{A : Type (n+1)}. Esta propiedad evita que ocurran conversiones implítias y facilita la inferencia de tipos de Lean. Sin embargo, en la práctica Lean se encarga de realizar ciertas conversiones de manera automática, por lo que rara vez es necesario trabajar explícitamente con los universos.

\subsubsection{Tipos inductivos}

En Lean, la gran mayoría de tipos son instancias de una familia de tipos conocidos como \textbf{tipos inductivos}. Un tipo inductivo es una estructura formada por una lista finita de constructores, cada uno con su tipo correspondiente. Cada constructor describe una forma válida de construir un término de este nuevo tipo.

En Lean, definimos un tipo inductivo utilizando la palabra clave \bluecode{inductive}\footnote{Aunque en Lean los tipos inductivos se introducen como una construcción primitiva del lenguaje, pueden definirse de manera equivalente sólo en términos de tipos dependientes. Esta reducción se explora formalmente en \cite{carneiro2019type}.}.

\begin{lstlisting}
  inductive Foo where
    | constructor₁ : ... → Foo
    | constructor₂ : ... → Foo
    ...
    | constructorₙ : ... → Foo
\end{lstlisting}

Un ejemplo clásico de definición inductiva es el conjunto de los números naturales, $\mathbb{N}$. En Lean, podríamos describir el tipo \code{Nat} de los números naturales como

\begin{lstlisting}
  inductive Nat where
    | zero : Nat
    | succ : Nat → Nat
\end{lstlisting}

Internamente, la declaración \bluecode{inductive} genera automáticamente una colección de axiomas que definen el tipo:

\begin{itemize}
  \item Una constante, \code{Nat}, que representa el nuevo tipo.
  \item Una serie de reglas de introducción o constructores, que indican las posibles formas de construir términos del nuevo tipo. 
  \item Una regla de eliminación, \code{Nat.rec}, que indica la forma de \quotes{usar} un término de este tipo\footnote{El comando \bluecode{\#print} muestra la definición completa del objeto, a diferencia de \bluecode{\#check}, que solo muestra su tipo.}.
  \begin{lstlisting}
  #print Nat.rec
      -- recursor Nat.rec.{u}  :  {motive : ℕ → Sort u} → motive Nat.zero → ((n : ℕ) → motive n → motive n.succ) → (t : ℕ) → motive t\end{lstlisting}\end{itemize}

Es decir, \bluecode{inductive} puede verse como \textit{azúcar sintáctico} que genera automáticamente el siguiente código en Lean\footnote{Estudiaremos el comando \bluecode{axiom} en detalle más adelante.}:

\begin{lstlisting}
  axiom (Nat : Type)
  axiom (zero : Nat)
  axiom (succ : Nat → Nat)
  axiom (Nat.rec : {motive : Nat → Sort u} → motive Nat.zero →
    ((n : Nat) → motive n → motive Nat.succ n) → (t : Nat) → motive t)
\end{lstlisting}

Este último objeto, \code{Nat.rec}, codifica el principio de inducción sobre los naturales\footnote{\code{Nat.rec} es un tipo que depende de \code{motive}, que es una propiedad cualquiera sobre los naturales. \code{Nat.rec} nos dice que si se cumple \code{motive} para \code{Nat.zero} (\code{motive Nat.zero}), entonces si para cada \code{n} (\code{n : Nat}) que cumpla \code{motive} (\code{motive n}) se tiene que \code{n+1} cumple \code{motive} (\code{motive Nat.succ n}), entonces se cumple \code{motive} para cualquier \code{n} (\code{(t : Nat) → motive t}).}. Este principio se utiliza implícitamente en muchas definiciones por casos, como por ejemplo:

\begin{lstlisting}
  def add (m n : Nat) : Nat :=
    match n with
    | Nat.zero   => m
    | Nat.succ n => Nat.succ (add m n)
\end{lstlisting}

\newpage

En esta definición, utilizamos la expresión \code{match n with} para distinguir los dos posibles casos de un número natural: \code{zero} y \code{succ n}. Internamente, Lean compila esta expresión como una aplicación de \code{Nat.rec}. Veremos más adelante cómo este principio de inducción puede utilizarse no solo para definir funciones, sino también para probar propiedades sobre todos los términos de un tipo inductivo.

Finalmente, mediante los tipos inductivos es posible definir los conectores lógicos (negación, conjunción, disyunción e implicación). Esto constituye otra gran diferencia entre la teoría de conjuntos y el cálculo de construcciones inductivas. Para utilizar la teoría de conjuntos, es necesario haber desarrollado previamente la lógica (de primer orden). De esta manera, las demostraciones formales no constituyen objetos matemáticos, sino que viven exclusivamente en el plano metateórico.

En el cálculo de construcciones inductivas, en cambio, la lógica se expresa dentro de la misma teoría, y las demostraciones son objetos matemáticos que viven dentro de ella.

\subsubsection{Las demostraciones como objeto matemático}

Las proposiciones, como cualquier otro objeto en esta teoría, son términos con un tipo asociado. En Lean, este tipo recibe el nombre de \code{Prop}.

\begin{lstlisting}
  #check Prop    -- Prop : Type
  variable (P : Prop)
  #check P    -- P : Prop
  #check True    -- True : Prop
  #check ¬ P    -- ¬ P : Prop
\end{lstlisting}

Dado \code{p} un elemento de tipo \code{Prop} (\code{p : Prop}), podríamos introducir un nuevo tipo dependiente de \code{p}, \code{Proof p}. Diríamos que un término de tipo \code{Proof p} es una demostración de \code{p}.

Sin embargo, en lugar de introducir este nuevo tipo, intepretamos una proposición \code{p : Prop} como un tipo en si mismo, en particular, el tipo de las demostraciones de \code{p}. Entonces una expresión de la forma \code{h : p} quiere decir que \code{h} es una demostración de \code{p}. Tiene entonces sentido decir que una proposición \code{p} es verdadera si podemos construir término de tipo \code{p}.

\begin{lstlisting}
  variable (p : Prop)
  variable (h : p)
  #check h    -- h : p
\end{lstlisting}


Esto, junto con la teoría de tipos dependientes, nos proporciona una forma de definir cualquier resultado matemático: por ejemplo, \quotes{ser par} es una propiedad que depende de un número natural $n$, por lo que podríamos describirlo mediante \code{es\_par : $\mathbb{N} \to$ Prop}. Para cada \code{n} natural, obtenemos un término de tipo \code{Prop}.

\begin{lstlisting}
  def es_par : ℕ → Prop := ...
  #check es_par    -- es_par : ℕ → Prop
  #check es_par 3    -- es_par 3 : Prop
\end{lstlisting}

En este caso, un término de tipo \code{es\_par n} será una prueba de que \code{n} es par.

Además, si \code{p : Prop} es una proposición, Lean reconoce cualesquiera dos elementos de tipo \code{p} (\code{h1 h2 : p}) como iguales por definición: no importa qué prueba concreta tengamos, sólo importa su existencia. Esto se conoce como \quotes{irrelevacia de las demostraciones} (\textit{proof irrelevance}).

Por lo anterior, dadas dos proposiciones \code{p q : Prop}, podemos identificar los términos de tipo \code{Implies p q} (pruebas de \code{Implies p q}) con los términos de tipo \code{p $\to$ q}; si \code{h : Implies p q}, entonces \code{h} es una prueba de que \code{p} implica \code{q}, y por tanto podemos verlo como una función que, dada una prueba de \code{p}, devuelve una prueba de \code{q}. El conector \code{Implies} es por tanto redundante, y en lo que sigue utilizaremos sólo la expresión \code{$\to$}.

En resumen, para poder expresar un resultado matemático en este lenguaje, tenemos que escribir un término de la forma \code{p : Prop}. Para probar que el resultado es cierto, debemos construir un término \code{h : p}. El trabajo de Lean como asistente de demostración es verificar que el término \code{h} está bien construido y tiene el tipo correcto.


\subsection{¿Por qué fiarnos de Lean?}

Ahora que hemos descrito la manera en la que un resultado se considera demostrado en Lean, tiene sentido hacerse la pregunta: ¿por qué deberíamos fiarnos de la inferencia de tipos de Lean? ¿Qué garantías tenemos de que las demostraciones que Lean acepta, son realmente correctas? 

Como hemos mencionado, la responsabilidad de verificar que las construcciones que hacemos son correctas según las reglas formales del sistema recae sobre el núcleo (o \textit{kernel}) de Lean. El kernel es un pequeño programa que contiene la implementación mínima de la lógica interna de Lean.

El resto de componentes de Lean con el que interactuamos para construir demostraciones (como por ejemplo las tácticas que veremos después) devuelven construcciones expresadas en el lenguaje del kernel de Lean \cite{bailey2024type}. Esto quiere decir que confiar en Lean realmente se reduce a confiar en su kernel\footnote{Esta idea se conoce como \textit{criterio de de Bruijn}, que propone que un verificador formal debe producir sus pruebas en el lenguaje de un núcleo pequeño, incluso aunque utilicen otros métodos más complicados para construir dichas pruebas a priori \cite{bailey2024type}.}.

Ahora, ¿por qué nos fiamos del kernel de Lean? Gracias a que el kernel es pequeño y está aislado del resto del sistema, es posible escribir implementaciones independientes del mismo que verifiquen de manera autónoma las demostraciones aceptadas por Lean\footnote{Un ejemplo de esto es \textit{trepplein} \cite{ebner2022trepplein}, una herramienta que comprueba desmotraciones escritas en Lean 3 mediante una implementación propia, escrita en Scala.}. Lean permite exportar estas demostraciones en un formato intermedio que contiene toda la información necesaria para reconstruirlas y validarlas externamente. Además, puesto que este formato modular, es posible validar solo ciertos aspectos del kernel, como la inferencia de tipos o la evaluación de términos \cite{bailey2024type}.


\subsection{Demostraciones en Lean}

Para nuestro fin, nos centraremos en la función de asistente de demostración de Lean. A continuación vamos a introducir las herramientas principales que utilizaremos a la hora de formalizar resultados en Lean 4.

Guión de esta sección:

\begin{itemize}
  \item Definiciones
  \item Variables
  \item Proposiciones
  \item Demostraciones
  \item Infoview y modo táctico
  \item Tácticas
  \item Cómo utilizar Mathlib
  \item Noncomputable: el axioma de elección
\end{itemize}




\subsubsection{Definiciones}

Podemos definir constantes en Lean utilizando el comando \bluecode{def} y el operador \code{:=}. Por ejemplo:

\begin{lstlisting}
  def x : ℕ := 2
  def X : Type := ℕ
\end{lstlisting}

Cuando hacemos definiciones también podemos declarar el tipo de objeto que estamos definiendo. Esto no es necesario siempre, porque Lean puede, en general, inferir el tipo directamente.

\begin{lstlisting}
  #check X            -- output: X : Type
  def Y := ℝ
  #check Y            -- output: Y : Type
\end{lstlisting}

\begin{lstlisting}
  def y := 0
  #check y            -- output: y : ℕ
  def z := (0 : ℝ)
  #check z            -- output: z : ℝ
\end{lstlisting}

También podemos definir funciones utilizando el operador \bluecode{fun} (o \bluecode{$\lambda$}), y evaluar estas funciones en elementos concretos utilizando \bluecode{$\#$eval}.

\begin{lstlisting}
  def f : ℕ → ℕ := fun x ↦ x + 5
  def g : ℕ → Prop :=  λ x ↦ x > 0

  #eval f 4            -- output: 9
  #eval f x            -- output: 7
  #eval g 2            -- error: no sabe decidir inmediatamente si 2 > 0
\end{lstlisting}


\subsubsection{Resultados}

Un resultado consiste de varios elementos: el tipo de enunciado (ejemplo, lema o teorema), un nombre, unas hipótesis y una tesis.

Para diferenciar el tipo de enunciado utilizaremos las palabras clave \bluecode{example}, \bluecode{lemma} y \bluecode{theorem} [no se si hay alguno más]. Los resultados de tipo ejemplo no se identifican con un nombre. En el caso de los lemas y los teoremas, el nombre se escribe directamente detrás de la palabra clave.

Las hipótesis, que son opcionales, se escriben después del nombre, utilizando paréntesis para separarlas entre sí. Las hipótesis incluyen objetos que se inicializan (ej. "Sea $n \in \mathbb{N}$" se podría escribir como \code{(n : $\mathbb{N}$)}) y también hipótesis propiamente dichas que suponemos como ciertas. Estas últimas necesitan un nombre seguido de \code{:} (ej. "Supongamos que $n > 0$" se podría escribir como \code{(hn : n > 0)}).

A su vez, utilizamos los dos puntos \code{:} para separarlas de la tesis, que se escribe a continuación.

Al final de la expresión escribimos \code{:=}, y después de este símbolo escribiremos la demostración del enunciado. Por ahora ignoraremos esa parte.

Ejemplos:

\begin{lstlisting}
  example : 2 + 2 = 4 := ...

  lemma my_obvious_lemma (P : Prop) : P → P := ...

  theorem modus_ponens (P Q : Prop) (hP : P) (hPQ : P → Q) : Q := ...

  lemma i_am_error (P Q : Prop) (h : P) : Q := ... 
\end{lstlisting}

En el último ejemplo quería destacar que Lean no pone ninguna pega a un resultado que no sea cierto, este último resultado no dará ningún error (salvo un mensaje de que queda por demostrar). Lean no comprueba la veracidad de los enunciados, sólo comprueba si la demostración a continuación es correcta.

\subsubsection{Mathlib}

[No se donde poner esta sección si antes de defs y resultados o despues o incluso dentro de pruebas??]

La librería de matemáticas de Lean, \textit{Mathlib}, es un proyecto colaborativo con el objetivo de construir una base de datos unificada de definiciones y resultados matemáticos formalizadas en el lenguaje Lean, y cuenta con numerosos colaboradores habituales y actividad diaria\cite{leanprover2024}.

Cómo utilizamos Mathlib?? <- esto es importante

Keywords: exact?, apply?, rw?

Todas sirven para buscar en la librería de mathlib (o en los resultados anteriores que hayamos escrito nosotros) y aplicar la táctica correspondiente.

\subsubsection{Pruebas}

[Muchos ejemplos de esta parte en cierto sentido están sacados del curso de Buzzard y demás. No se como debería escribir esas citas xd]

En Lean, existen dos formas de formalizar demostraciones: utilizando términos y utilizando tácticas. Una prueba es un objeto de tipo \bluecode{Proof}. Un término de tipo \bluecode{Proof} es una representación de una demostración matemática de la veracidad de un enunciado.

Para el objetivo de este trabajo, nos vamos a centrar en las demostraciones que utilizan tácticas. Una demostración de tipo táctico en Lean consiste en una sucesión de comandos o instrucciones, a las que llamamos tácticas, que describen cómo se construye la demostración.

Una vez hemos descrito un resultado o enunciado en Lean, si después de \code{:=} escribimos la palabra clave \bluecode{by}, entraremos en lo que llamamos \textit{modo táctico}. El modo táctico tiene dos particularidades:

Por un lado, contamos en nuestro editor con una nueva ventana llamada \textit{Lean Infoview} que ahora mostrará una lista de elementos. Por ejemplo, si en nuestro archivo lean tenemos lo siguiente

\begin{lstlisting}
  theorem modus_ponens (P Q : Prop) (hP : P) (hPQ : P → Q) : Q := by
\end{lstlisting}

En el infoview ahora veremos lo siguiente:

\begin{lstlisting}
  P Q : Prop
  hP : P
  hPQ : P → Q
  ⊢ Q
\end{lstlisting}

Las tres primeras líneas se corresponden con las hipótesis de nuestro enunciado. La última línea, que siempre comienza con el símbolo \code{$\vdash$}, muestra nuestra tesis, es decir, lo que queremos demostrar en este momento.

Cuando aplicamos una táctica (escribimos un comando) las hipótesis y/o la tesis se actualizan automáticamente en el infoview. Aplicando una táctica detrás de otra, queremos modificar la tesis hasta llegar a algo que es cierto trivialmente. En este caso, el infoview mostrará el mensaje \code{No goals}. Sabremos entonces que hemos completado la prueba correctamente.

En general, y sobretodo en los casos sencillos, existe una relación bastante clara entre estos comandos (tácticas) y las expresiones que utilizamos en las demostraciones formales a las que estamos acostumbrados.

A continuación vamos a ver una a una las tácticas que más se utilizan en las demostraciones.

[NOTA : NO SE SI HACERLO COMO ESTÁ O DEFINIR LAS VARIABLES AL PRINCIPIO NO SE QUE ES MENOS LIOSO]

\begin{itemize}
    \item \textbf{\blue{intro}}
\end{itemize}
    
Imaginemos que queremos demostrar un resultado del estilo de "Si A, entonces B". Normalmente, empezaríamos la demostración diciendo "Supongamos que se da A. Veamos que entonces se tiene B".

En el modo táctico, utilizamos la táctica \bluecode{intro} con esta finalidad. Si en el infoview tenemos

\begin{lstlisting}
  A B : Prop
  ⊢ A → B
\end{lstlisting}

Y escribimos \code{\blue{intro} hA}, donde \code{hA} es el nombre que le queremos dar a la nueva hipótesis, obtendremos

\begin{lstlisting}
  A B : Prop
  hA : A        -- supongamos A
  ⊢ B           -- queremos ver si B
\end{lstlisting}

Por ejemplo, la demostración de nuestro lema \code{my\_obvious\_lemma} debería empezar de la siguiente forma

\begin{lstlisting}
  lemma my_obvious_lemma (P : Prop) : P → P := by
    intro hP
    sorry
\end{lstlisting}

Otra forma de utilizar \bluecode{intro} es en las expresiones de la forma "Para todo $x \in X$, $x$ tiene la propiedad $P$". Normalmente, empezaríamos diciendo "sea un $x \in X$ fijo pero arbitrario... veamos que $x$ satisface $P$".

También utilizaremos \bluecode{intro} en este caso. Si tenemos

\begin{lstlisting}
  P : X → Prop
  ⊢ ∀ (x : X), P x
\end{lstlisting}

y utilizamos \code{\blue{intro} x}, donde \code{x} es la nueva variable que vamos a definir, obtendremos

\begin{lstlisting}
  P : X → Prop
  x : X       -- sea x ∈ X
  ⊢ P x       -- veamos que x cumple P
\end{lstlisting}

\begin{itemize}
  \item \textbf{\textcolor{red}{sorry}}
\end{itemize}

Notemos que en el apartado anterior, la demostración de \code{my\_obvious\_lemma} termina con \redcode{sorry}. Esta es una táctica también, que indica a Lean que la demostración no está terminada, pero que no queremos terminarla por ahora.

Lean mostrará sobre los resultados que acaben en \redcode{sorry} la advertencia \code{declaration uses sorry}. Podemos utilizar resultados incompletos en otras pruebas, pero estas pruebas también estarán marcadas como incompletas.

\begin{itemize}
  \item \textbf{\blue{exact}}
\end{itemize}

Otra táctica fundamental es \bluecode{exact}. Usamos \bluecode{exact} cuando nuestra tesis sea literalmente igual o igual por definición\footnote{Para Lean, literalmente igual es lo mismo que igual por definición.} a una de nuestras hipótesis.

Con esta nueva táctica podemos terminar nuestra demostración de \code{my\_obvious\_lemma}; como en el infoview tenemos, despuñes de utilizar \code{\blue{intro} hP},

\begin{lstlisting}
  P : Prop
  hP : P
  ⊢ P
\end{lstlisting}

Enotnces podemos utilizar \code{\blue{exact} hP} para terminar.

\begin{lstlisting}
  lemma my_obvious_lemma (P : Prop) : P → P := by
    intro hP
    exact hP
\end{lstlisting}

Ahora, en el infoview obtendremos el mensaje \code{No goals}.

Veamos un ejemplo en el que en vez de tener una hipótesis literalmente igual que nuestra tesis, es igual por definición. Consideramos el resultado

\begin{lstlisting}
  example (A B : Set X)
      (x : X) (hx : x ∈ A ∧ x ∈ B) :
      x ∈ A ∩ B := by sorry
\end{lstlisting}

Tenemos un tipo $X$, subconjuntos $A, B \subset X$ y un elemento $x \in X$. Suponemos que $x \in A \land x \in B$ (\code{hx}). Queremos ver que $x \in A \cap B$. Pero, en Lean, $x \in A \cap B$ está definido como $x \in A \land x \in B$, luego realmente tenemos lo mismo. El resultado anterior se puede demostrar, por tanto, utilizando simplemente

\begin{lstlisting}
  example (A B : Set X)
      (x : X) (hx : x ∈ A ∧ x ∈ B) :
      x ∈ A ∩ B := by
    exact hx
\end{lstlisting}



\begin{itemize}
  \item \textbf{\blue{rfl}}
\end{itemize}

Utilizamos \bluecode{rfl} cuando tenemos en el objetivo una expresión con una igualdad, una doble implicación o cualquier otra relación de equivalencia, en la que los términos a ambos lados son exactamente iguales (o iguales por definición). Consiste en aplicar la propiedad reflexiva ($x \cong x$) de las relaciones de equivalencia.

Ejemplos:

\begin{lstlisting}
  example (x : X) : x = x := by
    rfl
\end{lstlisting}

\begin{lstlisting}
  example (A B : Set X) (x : X) :
      (x ∈ A ∪ B) ↔ (x ∈ A ∨ x ∈ B) := by
    rfl
\end{lstlisting}

\begin{itemize}
  \item \textbf{\blue{trivial}}
\end{itemize}

La táctica \bluecode{trivial} se utiliza cuando el objetivo es \code{True} o igual a \code{True} por definición. Ejemplos:

\begin{lstlisting}
  example : True := by
    trivial
\end{lstlisting}

En Lean, existe un subconjunto especial, el \code{Set.univ}, que contiene a todos los elementos del tipo asociado; es el universo, el todo. Por tanto, si $x \in X$, entonces \code{$x \in$ Set.univ} está definido simplemente como \bluecode{True}.

\begin{lstlisting}
  example (x : X) : x ∈ Set.univ := by
    trivial
\end{lstlisting}



\begin{itemize}
  \item \textbf{\textcolor{blue}{apply}}
\end{itemize}

La táctica \bluecode{apply} consiste en aplicar Modus Ponens. Si quiero demostrar B, y tengo como hipótesis "A implica B", entonces basta con demostrar A.

Es decir, si en el infoview tengo algo de la forma

\begin{lstlisting}
  P Q : Prop
  hPQ : P → Q
  ⊢ Q
\end{lstlisting}

y utilizo \code{\blue{apply} hPQ}, paso a tener P como objetivo:

\begin{lstlisting}
  P Q : Prop
  hPQ : P → Q
  ⊢ P
\end{lstlisting}

Con esto, ya podemos demostrar nuestro teorema \code{modus\_ponens}

\begin{lstlisting}
  theorem modus_ponens (P Q : Prop) (hP : P) (hPQ : P → Q) : Q := by
    apply hPQ
    exact hP
\end{lstlisting}

Notar que \bluecode{apply} también sirve para expresiones que aunque no sean implicaciones, son iguales a implicaciones por definición. Por ejemplo, en Lean, $A \subset B$ está definido como $x \in A \implies x \in B$. Por tanto, si tenemos en el infoview

\begin{lstlisting}
  A B : Set X
  x : X
  h : A ⊆ B
  ⊢ x ∈ B
\end{lstlisting}

Podemos utilizar \code{\blue{apply} h}, y la tesis pasará a ser

\begin{lstlisting}
  ⊢ x ∈ A
\end{lstlisting}

También podemos usar apply en otra hipótesis utilizando la palabra clave \blue{at}. Por ejemplo, supongamos que tenemos las hipótesis

\begin{lstlisting}
  hP : P
  hPQ : P → Q
\end{lstlisting}

Aplicar \code{\blue{apply} hPQ \blue{at} hP}, actualizaría las hipótesis a

\begin{lstlisting}
  hP : Q
  hPQ : P → Q
\end{lstlisting}



\begin{itemize}
  \item \textbf{\blue{by\_contra}}
\end{itemize}

Esta táctica es equivalente a utilizar el método de reducción al absurdo. Al aplicarla, añade una nueva hipótesis, resultante de negar la tesis, y la tesis pasa a ser \code{False}.

Por ejemplo, si tenemos en el infoview

\begin{lstlisting}
  ⊢ P
\end{lstlisting}

y aplicamos \code{\blue{by\_contra} h}, ahora tendremos

\begin{lstlisting}
  h : ¬P
  ⊢ False
\end{lstlisting}

Para poder demostrar la tesis \code{False}, necesitamos tener una hipótesis que sea igual o equivalente a \code{False}. También podemos tener dos hipótesis distintas que sean contradictorias (lo que normalmente conocemos como "llegar a una contradicción"). Si tenemos una hipótesis \code{h1}, y otra hipótesis \code{h2} es el resultado de contradecir \code{h1}, entonces podemos utilizar \code{\blue{exact} h2 h1} para demostrar \code{False}.

Podemos demostrar \code{my\_obvious\_lemma} utilizando reducción al absurdo:

\begin{lstlisting}
  lemma my_obvious_lemma (P : Prop) : P → P := by
    intro hP
    by_contra hNP       -- nueva hipotesis hNP : ¬P
    exact hNP hP        -- No Goals
\end{lstlisting}

Notar que si una de mis hipótesis es igual o equivalente a \code{False}, entonces puedo demostrar cualquier cosa. Por ejemplo:

\begin{lstlisting}
  example (h : x ∈ (∅ : Set X)) : 1 = 2 := by
    by_contra         -- no necesitamos la hipotesis 1 ≠ 2
    exact h           -- No Goals
\end{lstlisting}

En Lean, $x \in \emptyset$ está definido simplemente como \code{False}.



\begin{itemize}
  \item \textbf{Resumen de las tácticas básicas}
\end{itemize}

% poner bien el ancho de las filas :/

[Esto igual debería ir en un anexo? no se]

\renewcommand{\arraystretch}{2}

\begin{center}
\begin{tabular}{|  m{8em}  |m{8em} |m{8em}  |} 
  \hline
  \textbf{antes} & \textbf{táctica} & \textbf{después} \\
  \hline
  $\vdash$ P $\rightarrow$ Q & intro hP & \parbox{8em}{hP : P \\ $\vdash$ Q} \\ 
  \hline
  $\vdash \forall$x : X, P x & intro x &  \parbox{8em}{x : X \\ $\vdash$ P x} \\ 
  \hline
  \parbox{8em}{h : P \\ $\vdash$ P}& exact h & No goals\\ 
  \hline
  $\vdash$ x = x & rfl & No goals\\ 
  \hline
  $\vdash$ P $\leftrightarrow$ P & rfl & No goals\\ 
  \hline
  $\vdash$ True & trivial & No goals \\ 
  \hline
  \parbox{8em}{h : P $\rightarrow$ Q \\ $\vdash$ Q} & apply h & $\vdash$ P\\ 
  \hline
  \parbox{8em}{h1 : P $\rightarrow$ Q \\ h2 : P} & apply h1 at h2 & h2 : Q\\ 
  \hline
  $\vdash$ P & by\_contra h & \parbox{8em}{h : $\neg$ P \\ $\vdash$ False} \\\hline
\end{tabular}
\end{center}

\begin{itemize}
  \item \textbf{Utilizar resultados anteriores}
\end{itemize}

Como es habitual en matemáticas a menudo querremos escribir demostraciones que utilicen otros resultados que ya hayamos demostrado previamente. En este caso, podemos aplicar las tácticas anteriores, en particular \bluecode{exact} y \bluecode{apply}, utilizando resultados que ya hemos escrito.

Por ejemplo:

\begin{lstlisting}
  lemma lemma_exact (n : ℕ) : 2^n > 0 := by sorry

  example : 2^5 > 0 := by
    exact lemma_exact 5
\end{lstlisting}

Utilizo \bluecode{exact}, seguido del nombre del resultado que quiero usar y los parámetros que requiere este resultado (en este caso, requiere un número natural). De la misma forma utilizamos apply:

\begin{lstlisting}
  lemma lemma_apply (n : ℕ) : n ≥ 2 → 2^n > n := by sorry

  example : 2^5 > 5 := by
    apply lemma_apply 5        -- la tesis ahora es ⊢ 5 ≥ 2
    sorry
\end{lstlisting}

También podemos hacer referencia a definiciones que hayamos descrito antes

\begin{lstlisting}
  def es_par (n : ℕ) : Prop := ∃ m : ℕ, n = 2 * m

  example : es_par 2 := by sorry
\end{lstlisting}


\begin{itemize}
  \item \textbf{Utilizar los resultados de Mathlib}
\end{itemize}

Además de utilizar los resultados que nosotros hayamos probado antes, es especialmente interesante poder utilizar los resultados que ya están demostrados en la librería de matemáticas de Lean, Mathlib. Sin embargo, encontrar el nombre del resultado que necesitamos en cada momento puede ser complicado.

Contamos con una serie de tácticas que nos facilitan esta tarea. La táctica que más utilizaremos es \bluecode{exact?}. Al escribir \bluecode{exact?} en una demostración, Lean buscará en la librería un resultado que, al aplicar \code{\blue{exact} ese\_resultado}, concluya la prueba. Nos devolverá en el infoview una o varias opciones que podemos probar.

Por ejemplo,

\begin{lstlisting}
  lemma lemma_exact (n : ℕ) : 2^n > 0 := by
    exact?
\end{lstlisting}

nos devuelve en el infoview el mensaje: \code{Try this: \blue{exact Nat.two\_pow\_pos n}}. Podemos simplemente pinchar en la sugerencia y la escribirá sustituyeno a \bluecode{exact?}. Esto completará la prueba, pues \code{Nat.two\_pow\_pos} es un resultado de Mathlib igual o equivalente a nuestro lema. En efecto, si escribimos

\begin{lstlisting}
  #check Nat.two_pow_pos
\end{lstlisting}

Obtenemos el mensaje

\begin{lstlisting}
  Nat.two_pow_pos (w : ℕ) : 0 < 2 ^ w
\end{lstlisting}

La táctica \bluecode{exact?} también busca resultados que nosotros hayamos probado, así que también podemos utilizarlo cuando sepamos que algo ya lo hemos demostrado.

La táctica \bluecode{apply?} funciona de la misma forma, aunque suele sugerir una gran cantidad de resultados distintos y, a menudo, muchos no son realmente útiles.


[No se si poner algo de que a veces no funciona exact? pero podemos intentar como escribir lo que estamos buscando asi generalmente en un ejemplo aparte y ya ver si lo puedes aplicar en tu demo (es como una cosa que hago todo el rato)]


\begin{itemize}
  \item \textbf{Simplificar expresiones}
\end{itemize}


Varias tácticas nos pueden servir para simplificar expresiones. Por un lado tenemos \bluecode{rw} (rewrite). Esta táctica toma entre corchetes una expresión (una hipótesis o un resultado) que sea una equivalencia (como $x = y$ o $P \leftrightarrow Q$) e intenta reescribir cada instancia en la tesis de la parte izquierda de la equivalencia por la parte derecha. Una definición también se considera una equivalencia.

Por ejemplo, el siguiente resultado

\begin{lstlisting}
  example (a b : ℕ) (h : a = b) : es_par (a + b) := by sorry
\end{lstlisting}

imprime en el infoview

\begin{lstlisting}
  a b : ℕ
  h : a = b
  ⊢ es_par (a + b)
\end{lstlisting}

Si ahora escribimos \code{\blue{rw} [h]}, entonces la tesis pasará a ser

\begin{lstlisting}
  ⊢ es_par (b + b)
\end{lstlisting}

Ahora podemos escribir \code{\blue{rw} [es\_par]}, y la tesis cambiará a

\begin{lstlisting}
  ⊢ ∃ m, b + b = 2 * m
\end{lstlisting}

También podemos utilizar \code{\blue{rw} [ · ] \blue{at} h} para aplicar los cambios a una hipótesis \code{h} en lugar de la tesis, y \code{\blue{rw} [ · ] \blue{at} *} para aplicarlos en todas las expresiones posibles.

Para hacer el camino inverso, cambiar las instancias de la parte derecha de la equivalencia a la parte izquierda, utilizamos la flecha hacia la izquierda: \code{\blue{rw} [$\leftarrow$  · ]}.

Una táctica bastante más simple que esta es \bluecode{simp}, que intenta simplificar la tesis utilizando todos los resultados y definiciones posibles de Mathlib (que estén marcados como simplificaciones) y reescribiendo la expresión. 

Existen otras tácticas más particulares, como \bluecode{dsimp}, que funciona como \bluecode{simp} pero sólo utiliza definiciones (y no resultados), o \bluecode{ring}, que utiliza resultados relacionados con anillos para simplificar expresiones.

En el fondo, estas últimas tácticas hacen lo mismo que \bluecode{rw}, pero sin necesitar el paso de buscar en la librería.

\begin{itemize}
  \item \textbf{Conectores lógicos}
\end{itemize}

Algunas de nuestras hipótesis o tesis tendrán conectores lógicos más complicados como $\land$, $\lor$ y $\leftrightarrow$. Esto significará que tendremos que dividir la demostraciones en varias tesis más simples (por ejemplo, si quiero demostrar que se dan A y B, primero demuestro A y luego B).

Cuando trabajemos con varias tesis a la vez, podremos ver arriba del InfoView el número de tesis activas que tenemos, y a continuación veremos la primera tesis, seguida de la siguiente.

Para poder trabajar sólo con una tesis a la vez, por claridad, podemos separar las tesis utilizando puntos \code{·}. Cada punto simboliza una hipótesis distinta.

A continuación vamos a ver varios ejemplos en los que necesitamos trabajar con varias hipótesis, en particular cuando trabajemos con los conectores lógicos $\land$, $\lor$ y $\leftrightarrow$


\begin{enumerate}[label=\alph*., left=35pt]
  \item \textbf{$\lor$ en la tesis: \blue{left}, \blue{right}}
\end{enumerate}

El caso más sencillo es aquel en el que la tesis es de la forma "A o B", y sabemos que se tiene A (o B). En ese caso, utilizaremos la táctica \bluecode{left} (respectivamente \bluecode{right}) para simplificar la tesis.

Por ejemplo, si tenemos en el infoview

\begin{lstlisting}
  P Q : Prop
  h : P
  ⊢ P ∨ Q
\end{lstlisting}

y escribimos

\begin{lstlisting}
  example (P Q : Prop) (h : P) : P ∨ Q := by
    left
\end{lstlisting}

ahora tendremos

\begin{lstlisting}
  P Q : Prop
  h : P
  ⊢ P
\end{lstlisting}

Además, en hipótesis de la forma "A y B", podemos querer utilizar sólo A (o sólo B). Podemos utilizar \code{h.left} (respectivamente \code{h.right}). Por ejemplo

\begin{lstlisting}
  example (P Q : Prop) (h : P ∧ Q) : Q := by
    exact h.right
\end{lstlisting}



\begin{enumerate}[resume, label=\alph*., left=35pt]
  \item \textbf{$\lor$ en las hipótesis: \blue{cases'}}
\end{enumerate}

La táctica \bluecode{cases'}

La táctica "cases'"\footnote{existe una táctica cases pero es menos potente que esta, y esta es la que utilizaremos normalmente} se utiliza sobre una hipótesis de la forma "P $\lor$ Q", y queremos proceder de forma distinta en caso de que P y de que Q.

Es el equivalente a dividir una demostración en casos en el lenguaje natural. Movida: esto genera varios goals. Esto habría que explicarlo bien. Poner que gestionamos los distintos goals con · ?

Esta táctica también tiene otro uso práctico interesante para $\land$ : si se aplica a una hipótesis de la forma "P $\land$ Q", dividimos esta hipótesis en dos. Esto nos puede servir en ocasiones para simplificar las hipótesis y trabajar más fácilmente con ellas.

\begin{itemize}
    \item \textbf{constructor}
\end{itemize}

Podemos utilizar costructor cuando tengamos tesis que se puedan separar en dos partes, por ejemplo tesis de la forma "P $\land$ Q" se convierten en dos tesis distintas, por un lado P y por otro Q. Igualmente, tesis de la forma "P $\leftrightarrow$ Q" se divide en "P $\rightarrow$ Q" y "Q $\rightarrow$ P".


\begin{center}
\begin{tabular}{ | m{8em} | m{8em}| m{8em} | } 
  \hline
  \textbf{antes} & \textbf{táctica} & \textbf{después} \\
  \hline
  $\vdash$ P $\lor$ Q & left & $\vdash$ P \\
  \hline
  $\vdash$ P $\lor$ Q & right & $\vdash$ Q \\
  \hline
  \parbox{8em}{h : P $\lor$ Q \\ $\vdash$ goal} & cases' h with hP hQ & \parbox{8em}{goal 1: \\ hP : P \\ $\vdash$ goal \\[1ex] goal 2: \\ $~~$ hQ : Q \\ $~~$ $\vdash$ goal} \\
  \hline
  h : P $\land$ Q & cases' h with hP hQ & \parbox{8em}{hP : P \\ hQ : Q }\\
  \hline
  
\end{tabular}
\end{center}

\section{Espacios topológicos en Lean}

Explicar algunos ejemplos de definiciones y demostraciones, no a modo de explicación completa de los prerrequisitos de topoogía sino para tener un primer acercamiento sencillo a la topología en Lean.

\subsection{Espacios topolǵicos normales}

Introducción : ¿por qué son interesantes?

\begin{definition}
  Sea $X$ un espacio topológico. $X$ es \emph{normal} si para cada par de cerrados disjuntos $C, D \subseteq X$ existen abiertos disjuntos $U$ y $V$ en $X$ tales  que separan $C$ y $D$, es decir, $C \subseteq U$ y $D \subseteq V$ \textnormal{(véase \cite[p. 99]{willard2012general})}.
\end{definition}

En Lean, escribimos esta definición de la siguiente forma.

\begin{lstlisting}
  def NormalTopoSpace {X : Type} (T : TopologicalSpace X) : Prop :=
    ∀ C : Set X, ∀ D : Set X,
    IsClosed C → IsClosed D → C ∩ D = ∅ →
    ∃ U : Set X, ∃ V : Set X,
      IsOpen U ∧
      IsOpen V ∧
      C ⊆ U ∧
      D ⊆ V ∧
      U ∩ V = ∅
\end{lstlisting}

Ahora queremos dar una caracterización para este tipo de espacios, que nos facilitará el trabajo más adelante.

\begin{proposition}[Caracterización de la normalidad]
  Sea $X$ un espacio topológico. $X$ es normal si y sólo si para cada abierto $U$ y cada cerrado $C$ de $X$ tales que $C \subseteq U$, existe un abierto $V \subset X$ de forma que $C \subseteq V \subseteq \overline{V} \subseteq U$.
\end{proposition}

En Lean, escribimos:

\begin{lstlisting}
  lemma characterization_of_normal {X : Type}
    (T : TopologicalSpace X) :
    NormalTopoSpace T ↔
      ∀ U : Set X, ∀ C : Set X, IsOpen U → IsClosed C → C ⊆ U →
      ∃ V : Set X, IsOpen V ∧ C ⊆ V ∧ (Closure V) ⊆ U := by sorry
\end{lstlisting}

\begin{proof}
  Veamos primero una implicación, y luego la otra (utilizamos \bluecode{constructor}).

  ($\implies$) Supongamos que $X$ es un espacio normal (\code{hT}) y sean $U$ un abierto (\code{hU}) y $C$ un cerrado (\code{hC}) tales que $C \subseteq U$ (\code{hCU}).

\begin{lstlisting}
    intro hT U C hU hC hCU
\end{lstlisting}
  
  Puesto que $X$ es normal, por la definición, para $C$ y $U^c$ cerrados en $X$ obtenemos $V_1$ y $V_2$ abiertos (\code{V1\_open}, \code{V2\_open}) disjuntos (\code{hV}) tales que $C \subseteq V_1$ (\code{hCV}) y $U^c \subseteq V_2$ (\code{hUV}).

\begin{lstlisting}
  obtain ⟨V1, V2, V1_open, V2_open, hCV, hUV, hV⟩ :=
    hT C Uᶜ
    hC
    (by exact isClosed_compl_iff.mpr hU)
    (by rw [ABdisjoint_iff_AsubsBc, compl_compl]; exact hCU)
\end{lstlisting}

  Por supuesto, en Lean tenemos que especificar por qué $U^c$ es cerrado y por qué $U^c \subseteq V_2$. Ahora tenemos una hipótesis de la forma

\begin{lstlisting}
  h : IsOpen V1 ∧ IsOpen V2 ∧ C ⊆ V1 ∧ Uᶜ ⊆ V2 ∧ V1 ∩ V2 = ∅
\end{lstlisting}
  
  Tomamos como $V$ el $V_1$ obtenido de esta forma,

\begin{lstlisting}
    use V1
\end{lstlisting}

  Queremos ver que satisface las condiciones que le pedimos:

\begin{lstlisting}
  ⊢ IsOpen V1 ∧ C ⊆ V1 ∧ Closure V1 ⊆ U
\end{lstlisting}
  
  Cómo tiene que cumplir tres condiciones, tendremos que utilizar \bluecode{constructor} varias veces. En primer lugar, $V_1$ es abierto por construcción. Además, $C \subseteq V_1$ también por construcción.

\begin{lstlisting}
    constructor
    · exact V1_open
    constructor
    · exact hCV
\end{lstlisting}

  Ahora queda demostrar que $\overline{V_1} \subseteq U$. Por un lado, tenemos que $V_1$ y $V_2$ son disjuntos, luego, en particular, como $V_2$ es abierto, se tiene que $\overline{V_1}$ y $V_2$ son disjuntos.

\begin{lstlisting}
    · apply disjointU_V_then_disjointClosureU_V V2_open at hV
      apply Set.disjoint_iff_inter_eq_empty.mpr at hV -- usamos la propiedad Disjoint de Lean
\end{lstlisting}

  Por otro lado, tenemos que $\overline{V_1} \subseteq U$ $\iff$ $V_1$ y $U^c$ son disjuntos. Basta ver que lo son utilizando lo anterior, sabiendo que $U^c \subseteq V_2$.

\begin{lstlisting}
      apply Set.disjoint_compl_right_iff_subset.mp
      exact Set.disjoint_of_subset_right hUV hV
\end{lstlisting}

  ($\Longleftarrow$) Procedemos de manera similar. Sean $C_1$, $C_2$ cerrados (\code{C1\_closed}, \code{C2\_closed}) disjuntos (\code{hC}). Podemos aplicar la hipótesis (\code{h}) al abierto $C_1^c$ y al cerrado $C_2$ para obtener obtener un abierto $V$ (\code{V\_open}) de manera que $C_2 \subseteq V \subseteq \overline{V} \subseteq C_1^c$ (\code{hV}).

\begin{lstlisting}
    intro h C1 C2 C1_closed C2_closed hC
    obtain ⟨V, V_open, hV⟩ :=
      h C1ᶜ C2
      (by exact IsClosed.isOpen_compl)
      C2_closed
      (by rw [← ABdisjoint_iff_AsubsBc, Set.inter_comm C2 C1]; exact hC)
\end{lstlisting}

  Ahora tomamos los abiertos $U_1 = \overline{V}^c$ y $U_2 = V$. Queremos ver que cumplen la condición de normalidad para $C_1$ y $C_2$.
  
\begin{lstlisting}
  IsOpen (Closure V)ᶜ ∧ IsOpen V ∧ C1 ⊆ (Closure V)ᶜ ∧ C2 ⊆ V ∧ (Closure V)ᶜ ∩ V = ∅
\end{lstlisting}
  
  En efecto, ambos son abiertos ($\overline{V}^c$ por ser el complementario de una clausura y $V$ por construcción).

\begin{lstlisting}
    constructor
    · simp
      exact closure_is_closed V
    constructor
    · exact V_open
\end{lstlisting}

  Además, $C_1 \subseteq \overline{V}^c$ es equivalente a $\overline{V} \subseteq C_1^c$, que es cierto por construcción de $V$, igual que $C_2 \subseteq V$.
  
\begin{lstlisting}
    constructor
    · apply Set.subset_compl_comm.mp
      exact hV.right
    constructor
    · exact hV.left
\end{lstlisting}

  Por último, se tiene

  $$
  \overline{V}^c \cap V = \emptyset \iff V \cap \overline{V}^c = \emptyset \iff
  V \subseteq \overline{V}^{cc} \iff V \subseteq \overline{V},
  $$

  que es cierto por las propiedades de la adherencia.

\begin{lstlisting}
    · rw [Set.inter_comm]
      rw [ABdisjoint_iff_AsubsBc]
      simp
      exact set_inside_closure V
\end{lstlisting}



  





  

  




\end{proof}



\section{El Lema de Urysohn}

Introducción:

Definición: espacio normal

Lema (de Urysohn):

Esta demostración es relativamente complicada en papel, pero todavía lo es más cuando intentamos completarla en Lean. Por claridad, dividimos la demostración en varios pasos.

La demostración en Lean empieza utilizando la táctica \bluecode{constructor}, que nos divide el objetivo en dos, uno para cada implicación. Nos centraremos primero en la segunda, que es la más sencilla.

\subsection{El recíproco}





Queremos 

Demostración


\subsection{Numerar los racionales}

Los racionales son denumerables, es decir existe una biyección entre $\nat$ y $\rat$.

En particular, existe una función $f : \nat \to Q$ donde $Q = \rat \cap [0, 1]$, de forma que

\begin{enumerate}
  \item $f$ es biyectiva
  \item $f(0) = 1$
  \item $f(1) = 0$
\end{enumerate}

A partir de ahora llamarmeos $f$ a esta función.

Demostración:

Demostración en Lean: [poner solo las partes importantes?]

\subsection{Una parte}

Sea $n \in \nat$ con $n > 1$. Como $$P_n = \{1, 2, \dots, n-1\}$$ es un conjunto finito y $f$ es sobreyectiva, existen $r$ y $s$ en $P_n$ (es decir, $r < n$ y $s < n$) tales que

\begin{equation} \label{cond_rs}
  f(r) < f(n) < f(s)
\end{equation}

y, además, estas son las mejores elecciones, es decir

\begin{enumerate}
  \item Si $m < n$ es tal que $f(m) < f(n)$, entonces $f(m) \leq f(r)$
  \item Si $m < n$ es tal que $f(n) < f(m)$, entonces $f(s) \leq f(m)$
\end{enumerate}

Además, como $f$ es inyectiva, estas elecciones son únicas.

Para cada $n > 1$, consideramos las funciones $r : \nat \to \nat$ y $s : \nat \to \nat$ que nos dan precisamente estos números $r$ y $n$.

--

Supongamos que hemos encontrado una función $G : \nat \to \mathcal{P}(X)$ que satisface las siguientes propiedades

\begin{enumerate}
  \item $G(0) = X \backslash C_2$
  \item $G(1) = V$ tal que $C_1 \subseteq V \subseteq \overline{V} \subseteq X \backslash C_2$
  \item Para cada $n \in \nat $, $G(n)$ es abierto en $X$
  \item Para cada $n \in \nat$, si $n>1$ entonces \begin{equation} \label{cond_Grs} \overline{G(r(n))} \subseteq G(n) \subseteq \overline{G(n)} \subseteq G(s(n)) \end{equation}
\end{enumerate}

Queremos probar que, en este caso, $G$ también cumple la siguiente propiedad:

\begin{equation} \label{cond_G}
  \forall n, m \in \nat, f(n) < f(m) \implies \overline{G(n)} \subseteq G(m)
\end{equation}


\begin{proof}

Sean $n, m \in \nat$ con $f(n) < f(m)$

Para empezar, como $f(n) < f(m)$, no puede ser $n=0$ ni $m=1$:

\begin{itemize}
  \item Si fuera $n = 0$, entonces $f(n) = 1$ y tendríamos $1 < f(m)$, pero $f$ toma valores en $[0, 1]$.
  \item Si fuera $m = 1$, entonces $f(m) = 0$ y tendríamos $f(n) < 0$, pero $f$ toma valores en $[0, 1]$.
\end{itemize}

Además, $n \neq m$ por ser $f$ inyectiva. Dividimos en los siguientes casos.

\textit{Caso 1.} $n = 1, m = 0$

Trivialmente por hipótesis (prop. 2 de G)

\textit{Caso 2.} $n > 1, m = 0$, por inducción completa sobre $n$

Sea $n>1$ arbitrario y supongamos, por inducción, que para cada $k < n$ con $k > 1$ se tiene $\overline{G(k)} \subseteq G(m)$.

Hay dos posibilidades: o bien $s(n)=0$ o bien $s(n)>1$. En el caso de que $s(n)=0$ es sencillo: tenemos $m=0=s(n)$, por tanto el objetivo pasa a ser $\overline{G(n)} \subseteq G(s(n))$, que es cierto por las propiedades de G.

Supongamos por tanto que $s(n)>1$. Entonces podemos aplicar la hipótesis de inducción a $k=s(n)>1$, y obtenemos que $\overline{G(s(n))} \subseteq G(m)$. Pero, por las propiedades de G,  $\overline{G(n)} \subseteq G(s(n))$. Obtenemos, por las propiedades de la adherencia,

$$\overline{G(n)} \subseteq G(s(n)) \subseteq \overline{G(s(n))} \subseteq G(m)$$

\textit{Caso 3.} $n = 1, m > 1$, por inducción completa sobre $m$

Es simétrico al anterior. Sea $m>1$ arbitrario y supongamos, por inducción, que para cada $l < m$ con $l > 1$ se tiene $\overline{G(n)} \subseteq G(l)$.

Hay dos posibilidades: o bien $r(m)=1$ o bien $r(m)>1$. En el caso de que $r(m)=1$ es sencillo: tenemos $n=1=r(m)$, por tanto el objetivo pasa a ser $\overline{G(r(m))} \subseteq G(m)$, que es cierto por las propiedades de G.

Supongamos por tanto que $r(m)>1$. Entonces podemos aplicar la hipótesis de inducción a $l=r(m)>1$, y obtenemos que $\overline{G(n)} \subseteq G(r(m))$. Pero, por las propiedades de G,  $\overline{G(r(m))} \subseteq G(m)$. Obtenemos, por las propiedades de la adherencia,

$$ \overline{G(n)} \subseteq G(r(m)) \subseteq \overline{G(r(m))} \subseteq G(m) $$

\textit{Caso 4.} $n > 1, m > 1$. Dividimos en dos casos adiccionales:

\textit{Caso 4.1.} $m < n$

Por inducción sobre $n$. Sea $n>m>1$ tal que $f(n) < f(m)$ y supongamos, por inducción, que para cada $k < n$ con $k>m$ y $f(k) < f(m)$ se tiene 

Sabemos que $m < n$ y que $f(n) < f(m)$. Por tanto, podemos aplicar las propiedades de $s$ sobre $n$ ($f(n) < f(s(n))$ es la mejor elección) y obtenemos que $f(s(n)) \leq f(m)$.

Si $f(s(n)) = f(m)$, como $f$ es inyectiva, $s(n)=m$. Luego es trivial porque el objetivo pasa a ser $\overline{G(n)} \subseteq G(s(n))$.

Supongamos que $f(s(n)) < f(m)$.

\textit{Caso 4.2.} $m < n$


Supongamos primero que $n = 1$ y $m = 0$. Entonces conocemos los valores de $G(n)$ y $G(m)$, y la expresión \refpep{cond_G} que queremos probar pasa a ser

$$
  \overline{V} \subseteq X \backslash C_2
$$

que es cierto por hipótesis.

Supongamos ahora que $n, m >1$. Entonces ambas satisfacen \refpep{cond_Grs}. Vamos a probar

\begin{equation} \label{cond_G_inductive}
  \forall n, m > 1, f(n) < f(m) \implies \overline{G(n)} \subseteq G(m)
\end{equation}

Nota:
En un caso extremadamente explicativo (pero para que fuera consistente en cierta manera con la demostración en Lean) quizás podría escribir que esta condición es equivalente a esta otra, sobre la que se puede aplicar inducción completa "normal":

$$
  \forall n, m \in \nat, f(n+2) < f(m+2) \implies \overline{G(n+2)} \subseteq G(m+2)
$$


Por inducción completa sobre $n$ y $m$.

Inducción sobre $n$.

\begin{itemize}
  \item \textit{Caso base} ($n = 2$).
\end{itemize}
  
Como $n=2$, y se tiene $r(n) < n$ y $s(n) < n$, podemos asegurar que $r(n), r(s) \in \{0, 1\}$.

En particular, para que se cumpla \refpep{cond_rs}, necesariamente tiene que ser $$0 = f(1) < f(2) < f(0) = 1$$ y por tanto $r(n) = 1$ y $s(n) = 0.$

Sea entonces un $m > 1$ fijo pero arbitrario. Sabemos que $m \neq 2$ por ser $f$ inyectiva.

Inducción sobre $m$

\begin{itemize}
  \setlength{\itemindent}{2em}
  \item[$\circ$] \textit{Caso base} ($n = 2, m= 3$)
\end{itemize}

Como $f(n) < f(m)$, se tiene $$0 < f(1) < f(2) < f(3) < f(0) = 1.$$ Por tanto, $r(m) = 2 = n$ y $s(m) = 0$. De \refpep{cond_Grs}, se obtiene:

$$
\overline{G(n)} = \overline{G(r(m))} \subseteq G(m),
$$

como queríamos.

\begin{itemize}
  \setlength{\itemindent}{2em}
  \item[$\circ$] \textit{Caso recursivo} ($n = 2, m>3$)
\end{itemize}

Hipótesis de inducción:

\begin{equation} \label{cond_G_ind_m}
  \forall l < m \text{ con } l > 1, f(2) < f(l) \implies \overline{G(2)} \subseteq G(l)
\end{equation}

Veamos primero que se tiene que dar $r(m) > 1$.

\begin{itemize}
  \item $r(m) \neq 0$. Si fuera $r(m) = 0$ tendríamos $1 = f(0) < f(m)$, que es imposible.
  \item $r(m) \neq 1$. Si fuera $r(m) = 1$, como $f(n) < f(m)$ y $r(m)$ es la mejor elección, tendríamos $f(n) \leq f(r(m)) = f(1) = 0$. Como $n=2\neq 1$, entonces $f(n) < 0$, que es imposible.
\end{itemize}


Luego $r(m)> 1$ y podemos aplicar \refpep{cond_G_ind_m} a $l=r(m)<m$, obteniendo $$\overline{G(2)} \subseteq G(r(m)).$$

Por otro lado, por \refpep{cond_Grs}, sabemos que $$\overline{G(r(m))} \subseteq G(m).$$ Mediante las propiedades de la adherencia, unimos las expresiones

$$
\overline{G(2)} \subseteq G(r(m)) \subseteq \overline{G(r(m))} \subseteq G(m),
$$

finalizando por tanto la inducción sobre $m$.

\begin{itemize}
  \item \textit{Caso recursivo} ($n > 2$, $m>1$ es fijo pero arbitrario)
\end{itemize}

Hipótesis de inducción:
\begin{equation} \label{cond_G_ind_n}
  \forall k < n \text{ con } k > 1, f(k) < f(m) \implies \overline{G(k)} \subseteq G(m)
\end{equation}

Tenemos que diferenciar dos casos: $s(n) = 0$ y $s(n) > 1$ (no puede ser $s(n) = 1$ porque en ese caso tendríamos $f(n) < f(s(n)) = f(1) = 0$, que es imposible).

Supongamos primero que $s(n) = 0$. Entonces, como $f(n) < f(m)$ y $s(n)$ es la mejor elección, tenemos que $f(s(n)) \leq f(m)$. Sin embargo, en realidad no puede darse $f(s(n)) < f(m)$, porque tendríamos $1 = f(0) = f(s(n)) < f(m)$, que es imposible. Luego en caso de que $s(n)=0$, necesariamente se tiene $f(s(n)) = f(m)$, y por inyectividad de $f$, $s(n) = m$. Entonces el resultado se sigue trivialmente de \refpep{cond_Grs} aplicado a $n>1$:

$$
  \overline{G(n)} \subseteq G(s(n)) = G(m).
$$

Si suponemos ahora que $s(n)>1$, podemos aplicar \refpep{cond_G_ind_n} a $k = s(n) < n$, obteniendo $$\overline{G(s(n))} \subseteq G(m).$$

Además, por \refpep{cond_Grs}, como $n > 1$, se tiene $$\overline{G(n)} \subseteq G(s(n)),$$ y, por las propiedades de la adherencia, podemos unir ambas expresiones $$\overline{G(n)} \subseteq G(s(n)) \subseteq \overline{G(s(n))} \subseteq G(m)$$ obteniendo el resultado que buscábamos.


\end{proof}

% Bibliografía

\bibliographystyle{myunsrt}
\bibliography{references.bib}

\end{document}
